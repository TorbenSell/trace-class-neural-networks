{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import gym\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "\n",
    "\n",
    "N_a = 3                             # number of possible actions (actions are -1, 0, and 1)\n",
    "sigma = 0.1                         # noise\n",
    "dim = 2                             # dimensionality of the space (v: R^d --> R)\n",
    "pCNL = False\n",
    "obs_min = np.array([-1.2,-0.07])\n",
    "obs_max = np.array([ 0.6, 0.07])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - VALUE FUNCTION AND POLICIES\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "''' Progress bar to know how much longer one has to wait '''\n",
    "def progressBar(value, endvalue, bar_length=40):\n",
    "    percent = float(value) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    sys.stdout.write(\"\\rPercent: [{0}] {1}%\".format(arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "''' u(x), which evaluates the function u at x=(pos,speed) with the currently set xi '''\n",
    "def u(x):\n",
    "    x_transformed = np.zeros(dim)\n",
    "    for i in range(dim):\n",
    "        x_transformed[i] = ((x[i]-obs_min[i])/(obs_max[i]-obs_min[i])-1/2)*2\n",
    "        \n",
    "    value = model_list[it](torch.from_numpy(x_transformed).float())\n",
    "    return value\n",
    "\n",
    "''' Policy from \"Reinforcement Learning: Theory and {Python} Implementation\" '''\n",
    "def policy(position,velocity):\n",
    "        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,\n",
    "                0.3 * (position + 0.9) ** 4 - 0.008)\n",
    "        ub = -0.07 * (position + 0.38) ** 2 + 0.07\n",
    "        if lb < velocity < ub:\n",
    "            action = 2 # push right\n",
    "        else:\n",
    "            action = 0 # push left\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROGRAMME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "MAIN PROGRAMME - SHOW LEARNED BEHAVIOUR\n",
    "\n",
    "\"\"\"   \n",
    "   \n",
    "env = gym.make('MountainCar-v0')\n",
    "env = env.unwrapped\n",
    "\n",
    "failures = np.zeros(3)\n",
    "steps = [[],[],[]]\n",
    "\n",
    "\n",
    "'''\n",
    "Behaviour following the optimal policy\n",
    "'''\n",
    "for _ in range(10):\n",
    "    pos_curr,speed_curr = env.reset()\n",
    "    for k in range(200):\n",
    "        pos_curr,speed_curr = env.step(policy(pos_curr,speed_curr))[0] \n",
    "        \n",
    "        if pos_curr>0.5:\n",
    "            steps[0].append(k)\n",
    "            break\n",
    "    if k==199:\n",
    "        failures[0]+=1\n",
    "print('Optimal policy done.')\n",
    "s = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'pCN'\n",
    "N_data = 50\n",
    "\n",
    "\"\"\" initialise NNs - pCN \"\"\"\n",
    "\n",
    "model_list = []\n",
    "\n",
    "# Hyperparameters for our network\n",
    "input_size = dim\n",
    "n_layer = 3\n",
    "hidden_sizes = [10,10,10]\n",
    "output_size = 1\n",
    "\n",
    "# Store hyperparameters in string\n",
    "hyps = str(hidden_sizes[0])\n",
    "for i in range(1,n_layer):\n",
    "    hyps = hyps+'_'+str(hidden_sizes[i])\n",
    "\n",
    "for it in range(1000):\n",
    "    # Build a feed-forward network\n",
    "    model_list.append(nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(hidden_sizes[-1], output_size)))\n",
    "\n",
    "    # Get weights\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for l in range(n_layer+1):\n",
    "        weights.append(np.load('np_saved/MC/samples_policy_learning/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_w'+str(l)+'_sampleNo'+str(it)+'.npy'))\n",
    "        biases.append(np.load('np_saved/MC/samples_policy_learning/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_b'+str(l)+'_sampleNo'+str(it)+'.npy'))\n",
    "        \n",
    "    # Set all weights to 0\n",
    "    for l in range(n_layer+1):\n",
    "        model_list[it][2*l].weight = torch.nn.Parameter(torch.from_numpy(weights[l]).float(), requires_grad=False)\n",
    "        model_list[it][2*l].bias = torch.nn.Parameter(torch.from_numpy(biases[l]).float(), requires_grad=False)\n",
    "\n",
    "\n",
    "\"\"\" run tests - pCN \"\"\"\n",
    "\n",
    "v = np.zeros(N_a)\n",
    "v_with_noise = np.zeros(N_a)\n",
    "\n",
    "errors = 0\n",
    "corrects = 0\n",
    "\n",
    "print('Test started: ' + str(time.ctime()))\n",
    "for _ in range(100):\n",
    "    pos_curr,speed_curr = env.reset()\n",
    "\n",
    "    for k in range(200):\n",
    "        progressBar(k+1,200)\n",
    "\n",
    "        ''' See where different actions would take us, evaluate mean of value function samples there '''\n",
    "        v = np.zeros(N_a)\n",
    "        for it in range(1000): # Iterate through different neural networks\n",
    "            for i in range(N_a):\n",
    "                x = env.step(i)[0]\n",
    "                v[i] += u(x).detach().numpy()[0]\n",
    "                env.state = [pos_curr,speed_curr]\n",
    "        v = v/1000 # to get mean of value function evaluations\n",
    "\n",
    "        ''' Pick action which maximises the mean value function (plus noise) at the new location '''\n",
    "        v_with_noise = v+sigma*np.random.normal(np.zeros(N_a),np.ones(N_a)) \n",
    "        a_argmax_with_noise = np.argmax(v_with_noise)\n",
    "\n",
    "        ''' Check whether learned action is the same as true action would be '''\n",
    "        if a_argmax_with_noise != policy(pos_curr,speed_curr):\n",
    "            errors+=1\n",
    "        else:\n",
    "            corrects+=1\n",
    "\n",
    "        pos_curr,speed_curr = env.step(a_argmax_with_noise)[0]\n",
    "\n",
    "        if pos_curr>0.5:\n",
    "            steps[s].append(k)\n",
    "            break\n",
    "    if k==199:\n",
    "        failures[s]+=1\n",
    "    progressBar(200,200)\n",
    "    print('\\n')\n",
    "\n",
    "print('Errorrate = ',(errors/(errors+corrects))) # Only makes sense if following learned policy\n",
    "s+=1\n",
    "print('pCN done, '+ str(time.ctime()))\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'pCNL'\n",
    "N_data = 50\n",
    "\n",
    "\"\"\" initialise NNs - pCNL \"\"\"\n",
    "\n",
    "model_list = []\n",
    "\n",
    "# Hyperparameters for our network\n",
    "input_size = dim\n",
    "n_layer = 3\n",
    "hidden_sizes = [10,10,10]\n",
    "output_size = 1\n",
    "\n",
    "# Store hyperparameters in string\n",
    "hyps = str(hidden_sizes[0])\n",
    "for i in range(1,n_layer):\n",
    "    hyps = hyps+'_'+str(hidden_sizes[i])\n",
    "\n",
    "for it in range(1000):\n",
    "    # Build a feed-forward network\n",
    "    model_list.append(nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                          nn.Tanh(),\n",
    "                          nn.Linear(hidden_sizes[-1], output_size)))\n",
    "\n",
    "    # Get weights\n",
    "    weights = []\n",
    "    biases = []\n",
    "    for l in range(n_layer+1):\n",
    "        weights.append(np.load('np_saved/MC/samples_policy_learning/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_w'+str(l)+'_sampleNo'+str(it)+'.npy'))\n",
    "        biases.append(np.load('np_saved/MC/samples_policy_learning/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_b'+str(l)+'_sampleNo'+str(it)+'.npy'))\n",
    "        \n",
    "    # Set all weights to 0\n",
    "    for l in range(n_layer+1):\n",
    "        model_list[it][2*l].weight = torch.nn.Parameter(torch.from_numpy(weights[l]).float(), requires_grad=False)\n",
    "        model_list[it][2*l].bias = torch.nn.Parameter(torch.from_numpy(biases[l]).float(), requires_grad=False)\n",
    "\n",
    "\n",
    "\"\"\" run tests - pCNL \"\"\"\n",
    "\n",
    "v = np.zeros(N_a)\n",
    "v_with_noise = np.zeros(N_a)\n",
    "\n",
    "errors = 0\n",
    "corrects = 0\n",
    "\n",
    "print('Test started: ' + str(time.ctime()))\n",
    "for _ in range(100):\n",
    "    pos_curr,speed_curr = env.reset()\n",
    "\n",
    "    for k in range(200):\n",
    "        progressBar(k+1,200)\n",
    "\n",
    "        ''' See where different actions would take us, evaluate mean of value function samples there '''\n",
    "        v = np.zeros(N_a)\n",
    "        for it in range(1000): # Iterate through different neural networks\n",
    "            for i in range(N_a):\n",
    "                x = env.step(i)[0]\n",
    "                v[i] += u(x).detach().numpy()[0]\n",
    "                env.state = [pos_curr,speed_curr]\n",
    "        v = v/1000 # to get mean of value function evaluations\n",
    "\n",
    "        ''' Pick action which maximises the mean value function (plus noise) at the new location '''\n",
    "        v_with_noise = v+sigma*np.random.normal(np.zeros(N_a),np.ones(N_a)) \n",
    "        a_argmax_with_noise = np.argmax(v_with_noise)\n",
    "\n",
    "        ''' Check whether learned action is the same as true action would be '''\n",
    "        if a_argmax_with_noise != policy(pos_curr,speed_curr):\n",
    "            errors+=1\n",
    "        else:\n",
    "            corrects+=1\n",
    "\n",
    "        pos_curr,speed_curr = env.step(a_argmax_with_noise)[0]\n",
    "\n",
    "        if pos_curr>0.5:\n",
    "            steps[s].append(k)\n",
    "            break\n",
    "    if k==199:\n",
    "        failures[s]+=1\n",
    "    progressBar(200,200)\n",
    "    print('\\n')\n",
    "\n",
    "print('Errorrate = ',(errors/(errors+corrects))) # Only makes sense if following learned policy\n",
    "s+=1\n",
    "print('pCNL done, '+ str(time.ctime()))\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Runtimes for different policies')\n",
    "ax1.boxplot(steps)\n",
    "plt.show()\n",
    "\n",
    "print(failures)\n",
    "\n",
    "np.save('BNN_steps.npy',np.array(steps))\n",
    "np.save('BNN_failures.npy',failures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# N_data=50\n",
    "# method='pCN'\n",
    "\n",
    "# mean = [[],[]]\n",
    "# for l in range(n_layer+1):\n",
    "#     mean[0].append(np.load('np_saved/MC/BNN_'+hyps+'_'+method+'_NData'+str(N_data)+'_lastSample_w'+str(l)+'.npy'))\n",
    "#     mean[1].append(np.load('np_saved/MC/BNN_'+hyps+'_'+method+'_NData'+str(N_data)+'_lastSample_b'+str(l)+'.npy'))\n",
    "\n",
    "# ''' both pCN and pCNL '''\n",
    "# for l in range(n_layer+1):\n",
    "#     model[2*l].weight = torch.nn.Parameter(torch.from_numpy(mean[0][l]).float(), requires_grad=False)\n",
    "#     model[2*l].bias = torch.nn.Parameter(torch.from_numpy(mean[1][l]).float(), requires_grad=False)\n",
    "    \n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# x = np.arange(-1.2,0.6,0.02)\n",
    "# y = np.arange(-0.07,0.07,0.002)\n",
    "# X,Y = np.meshgrid(x,y)\n",
    "# Z = np.zeros(X.shape)\n",
    "# for i in range(X.shape[0]):\n",
    "#     for j in range(X.shape[1]):\n",
    "#         Z[i,j] = u((X[i,j],Y[i,j]))[0]\n",
    "\n",
    "# ax.contourf(X,Y,Z)\n",
    "\n",
    "# fig.savefig('figs/MC_value_fn.pdf', dpi=300)\n",
    "# plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
