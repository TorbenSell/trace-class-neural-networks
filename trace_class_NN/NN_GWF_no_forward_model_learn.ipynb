{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Groundwater Flow example\n",
    "\n",
    "This example is taken from Beskos et al (2016) 'Geometric MCMC for infinite-dimensional inverse problems', and the notation largely follows their section 4, and we commented where we deviated from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import geom\n",
    "from torch import nn\n",
    "from copy import deepcopy as dc\n",
    "import numba\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['text.usetex'] = True\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False) #makes code very slow but one can find errors in backward()\n",
    "\n",
    "sigma = 0.01                        # noise, called sigma_y in the cited paper\n",
    "dim = 2                             # dimensionality of the space (v: R^d --> R)\n",
    "obs_min = np.array([0,0])\n",
    "obs_max = np.array([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "initialise NN\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Hyperparameters for our network\n",
    "input_size = 2*dim\n",
    "output_size = 1\n",
    "n_layer = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - PRIOR\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "''' Set sigma_w and sigma_b uniformly '''    \n",
    "alpha = 1.001  \n",
    "sigma_w_sq = np.ones(n_layer+1)*100\n",
    "sigma_b_sq = np.ones(n_layer+1)*100\n",
    "sigma_w_sq[-1] = 1/30\n",
    "sigma_b_sq[-1] = 1/10\n",
    "\n",
    "\n",
    "''' prior samples are represented by array of coefficients '''\n",
    "def sample_prior(c=1):\n",
    "    w = []\n",
    "    b = []\n",
    "    \n",
    "    ''' weights '''\n",
    "    w_layer = np.random.randn(model[0].weight.shape[0],model[0].weight.shape[1])*C_root[0][0]\n",
    "    w.append(c*w_layer)\n",
    "    \n",
    "    for l in range(1,n_layer):\n",
    "        w_layer = np.random.randn(model[2*l].weight.shape[0],model[2*l].weight.shape[1])*C_root[0][l]\n",
    "        w.append(c*w_layer)\n",
    "     \n",
    "    w_layer = np.random.randn(model[2*n_layer].weight.shape[0],model[2*n_layer].weight.shape[1])*C_root[0][-1]\n",
    "    w.append(c*w_layer)\n",
    "                \n",
    "    ''' biases '''\n",
    "    b_layer = np.random.randn(model[0].bias.shape[0])*C_root[1][0]\n",
    "    b.append(c*b_layer)\n",
    "    \n",
    "    for l in range(1,n_layer):\n",
    "        b_layer = np.random.randn(model[2*l].bias.shape[0])*C_root[1][l]\n",
    "        b.append(c*b_layer)\n",
    "     \n",
    "    b_layer = np.random.randn(model[2*n_layer].bias.shape[0])*C_root[1][-1]\n",
    "    b.append(c*b_layer)\n",
    "    \n",
    "    return [w,b]\n",
    "\n",
    "\n",
    "''' evaluate the log_prior up to a constant '''\n",
    "def logprior(xi):\n",
    "    log_prior = 0\n",
    "    w = xi[0]\n",
    "    b = xi[1]\n",
    "    \n",
    "    ''' weights '''\n",
    "    for l in range(n_layer+1):\n",
    "        log_prior += -0.5*np.sum(w[l]**2/C[0][l])\n",
    "        \n",
    "    ''' biases '''\n",
    "    for l in range(n_layer+1):\n",
    "        log_prior += -0.5*np.sum(b[l]**2/C[1][l])\n",
    "        \n",
    "    return log_prior\n",
    "\n",
    "\n",
    "def prior_proposal(xi):\n",
    "    log_prior_xi = logprior(xi)\n",
    "    \n",
    "    w = xi[0]\n",
    "    b = xi[1]\n",
    "    \n",
    "    ''' Firstly make a cpoy of the current state '''\n",
    "    w_proposal = []\n",
    "    b_proposal = []\n",
    "    for l in range(n_layer+1):\n",
    "        w_proposal.append(dc(w[l]))\n",
    "        b_proposal.append(dc(b[l]))\n",
    "    \n",
    "    random_l = np.random.randint(n_layer)\n",
    "    \n",
    "    ''' Sample index of function to be swapped '''\n",
    "    random_i = geom.rvs(1/alpha)\n",
    "    while random_i>=model[2*random_l].weight.shape[0]-1:  # -1???\n",
    "        random_i = geom.rvs(1/alpha)\n",
    "        \n",
    "    ''' swap f^l_i with f^l_{i+1}'''\n",
    "    w_proposal[random_l][random_i,:] = w[random_l][random_i+1,:]\n",
    "    w_proposal[random_l][random_i+1,:] = w[random_l][random_i,:]\n",
    "    w_proposal[random_l+1][:,random_i] = w[random_l+1][:,random_i+1]\n",
    "    w_proposal[random_l+1][:,random_i+1] = w[random_l+1][:,random_i]\n",
    "    b_proposal[random_l][random_i] = b[random_l][random_i+1]\n",
    "    b_proposal[random_l][random_i+1] = b[random_l][random_i]\n",
    "    \n",
    "    xi_proposal = [w_proposal,b_proposal]\n",
    "    log_prior_proposal = logprior(xi_proposal)\n",
    "    \n",
    "    a = np.exp(log_prior_proposal-log_prior_xi)\n",
    "    if np.random.uniform() < a:\n",
    "        counts[0] += 1\n",
    "        return xi_proposal\n",
    "    else:\n",
    "        counts[1] += 1\n",
    "        return xi\n",
    "    \n",
    "counts = np.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - LIKELIHOOD \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "m = 21\n",
    "\n",
    "\n",
    "def loglikelihood(y):\n",
    "    k = np.zeros(m**2)\n",
    "    for j in range(m):\n",
    "        for i in range(m):\n",
    "            k[i+m*j] = u((i/(m-1),j/(m-1))).detach().numpy()[0]\n",
    "    LL = -1/sigma**2*np.dot(k-y,k-y)/2\n",
    "    return LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - VALUE FUNCTION\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "''' u(x), which evaluates the function u at x '''\n",
    "def u(x):\n",
    "    x_transformed = np.zeros(dim)\n",
    "    for i in range(dim):\n",
    "        x_transformed[i] = ((x[i]-obs_min[i])/(obs_max[i]-obs_min[i])-1/2)*2\n",
    "        \n",
    "    x_transformed_again = np.zeros(2*dim)\n",
    "    for i in range(dim):\n",
    "        x_transformed_again[i] = x_transformed[i]\n",
    "        x_transformed_again[dim+i] = np.sin(x_transformed[i]*2*np.pi)\n",
    "        \n",
    "    value = model(torch.from_numpy(x_transformed_again).float())\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - ANALYTICS\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "''' Progress bar to know how much longer one has to wait '''\n",
    "def progressBar(t,value, t_max, acceptances, bar_length=40):\n",
    "    percent = float(t) / t_max\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    sys.stdout.write(\"\\rIteration: {0}    Acceptance ratio: {1}    Percent: [{2}] {3}%  \".format(value,round(acceptances/value,3),arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()    \n",
    "        \n",
    "''' Plotting a permeability '''    \n",
    "def func_plot(xi,name):\n",
    "    x = np.arange(0,1,0.005)\n",
    "    y = np.arange(0,1,0.005)\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    Z = np.zeros(X.shape)\n",
    "    \n",
    "    for l in range(n_layer+1):\n",
    "        model[2*l].weight = torch.nn.Parameter(torch.from_numpy(xi[0][l]).float(), requires_grad=False)\n",
    "        model[2*l].bias = torch.nn.Parameter(torch.from_numpy(xi[1][l]).float(), requires_grad=False)\n",
    "        \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Z[i,j] = np.exp(u((X[i,j],Y[i,j]))[0])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    c = ax.pcolormesh(X, Y, Z, cmap='cool', vmin=Z.min(), vmax=Z.max())\n",
    "    \n",
    "    # set the limits of the plot to the limits of the data\n",
    "    ax.axis([X.min(), X.max(), Y.min(), Y.max()])\n",
    "    fig.colorbar(c, ax=ax)\n",
    "    fig.savefig(name + '.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "''' Plotting a log permeability '''    \n",
    "def func_plot_log(xi,name):\n",
    "    x = np.arange(0,1,0.005)\n",
    "    y = np.arange(0,1,0.005)\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    Z = np.zeros(X.shape)\n",
    "    \n",
    "    for l in range(n_layer+1):\n",
    "        model[2*l].weight = torch.nn.Parameter(torch.from_numpy(xi[0][l]).float(), requires_grad=False)\n",
    "        model[2*l].bias = torch.nn.Parameter(torch.from_numpy(xi[1][l]).float(), requires_grad=False)\n",
    "        \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Z[i,j] = u((X[i,j],Y[i,j]))[0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    c = ax.pcolormesh(X, Y, Z, cmap='cool', vmin=-0.7, vmax=0.6)\n",
    "    \n",
    "    # set the limits of the plot to the limits of the data\n",
    "    ax.axis([X.min(), X.max(), Y.min(), Y.max()])\n",
    "    fig.colorbar(c, ax=ax)\n",
    "    fig.savefig(name + '.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "''' Plot a trajectory '''  \n",
    "def trajectory_plot(xi,name):\n",
    "    x = np.arange(len(xi))\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x,xi)\n",
    "    fig.savefig(name + '.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "''' Compute the autocorrelations '''    \n",
    "def autocorr(x,lags):\n",
    "    mean=np.mean(x)\n",
    "    var=np.var(x)\n",
    "    xp=x-mean\n",
    "    corr=[1. if l==0 else np.sum(xp[l:]*xp[:-l])/len(x)/var for l in lags]\n",
    "    return np.array(corr)\n",
    "\n",
    "''' Calculate the Effective Sample Size, assumes algorithm already burned in '''\n",
    "def ESS(logposterior,name):\n",
    "    fig, ax = plt.subplots()\n",
    "    N = len(logposterior)\n",
    "    ax.stem(autocorr(logposterior, range(int(N*0.1))),use_line_collection=True) \n",
    "    ESS = N/(1+2*sum(autocorr(logposterior, range(int(N*0.1)))))\n",
    "    print('Effective Sample Size:', round(ESS))\n",
    "    print('Samples required to generate 1 independent sample:', round(N/ESS,2))\n",
    "    fig.savefig(name + '.png', bbox_inches='tight')\n",
    "    plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - MCMC (pCN/pCNL)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def acceptance_prop(xi_u, xi_v,data,ll_u,diff_u=False):\n",
    "    accept_prop = -ll_u\n",
    "    \n",
    "    for l in range(n_layer+1):\n",
    "        model[2*l].weight = torch.nn.Parameter(torch.from_numpy(xi_v[0][l]).float(), requires_grad=True)\n",
    "        model[2*l].bias = torch.nn.Parameter(torch.from_numpy(xi_v[1][l]).float(), requires_grad=True)\n",
    "        \n",
    "    ll_v = loglikelihood(data)\n",
    "    accept_prop += ll_v\n",
    "    \n",
    "    return min(1, np.exp(accept_prop)),ll_v\n",
    "    \n",
    "def propose(xi,diff=False):\n",
    "    w = xi[0]\n",
    "    b = xi[1]\n",
    "    \n",
    "    noise = sample_prior()\n",
    "    w_noise = noise[0]\n",
    "    b_noise = noise[1]\n",
    "    \n",
    "    w_proposal = []\n",
    "    b_proposal = []\n",
    "    for l in range(n_layer+1):\n",
    "        w_proposal.append(np.zeros(model[2*l].weight.shape))\n",
    "        b_proposal.append(np.zeros(model[2*l].bias.shape))\n",
    "    \n",
    "    for l in range(n_layer+1):\n",
    "        w_proposal[l] = np.sqrt(1-beta*beta)*w[l]+beta*w_noise[l]\n",
    "        b_proposal[l] = np.sqrt(1-beta*beta)*b[l]+beta*b_noise[l]\n",
    "    return [w_proposal,b_proposal]\n",
    "\n",
    "def MCMC(xi,N_data,data,max_time):   \n",
    "    print('\\nMCMC algorithm ('+method + ', N_data=' + str(N_data) + ', ' + str(max_time) + ' seconds) was started: ' + str(time.ctime()))\n",
    "      \n",
    "    acc_ratio = 0\n",
    "    logposterior = []\n",
    "    logp = []\n",
    "    logl = []\n",
    "    \n",
    "    ''' Set model weights and biases to current iterate '''\n",
    "    for l in range(n_layer+1):\n",
    "        model[2*l].weight = torch.nn.Parameter(torch.from_numpy(xi[0][l]).float(), requires_grad=True)\n",
    "        model[2*l].bias = torch.nn.Parameter(torch.from_numpy(xi[1][l]).float(), requires_grad=True)\n",
    "        \n",
    "    ''' Initialise likelihood and gradient '''    \n",
    "    ll = loglikelihood(data)\n",
    "    print('Initial loglikelihood: ',ll)\n",
    "        \n",
    "    ''' Run MCMC '''\n",
    "    start = time.time() \n",
    "    j = 0\n",
    "    it = 0\n",
    "    while(time.time()-start<max_time):\n",
    "        \n",
    "        ''' Swap functions around to get mode switching '''\n",
    "        for _ in range(hidden_sizes[0]):\n",
    "            xi = prior_proposal(xi)\n",
    "        \n",
    "        ''' Propose and calculate acceptance probability '''\n",
    "        xi_proposal = propose(xi)  \n",
    "        a,ll_proposal = acceptance_prop(xi,xi_proposal,data,ll)\n",
    "        \n",
    "        ''' Accept or reject proposal '''\n",
    "        uni = np.random.uniform()\n",
    "        if uni < a:\n",
    "            xi = xi_proposal    \n",
    "            ll = ll_proposal\n",
    "            acc_ratio = acc_ratio + 1\n",
    "\n",
    "        ''' prior, likelihood, and posterior traceplots are appended '''\n",
    "        lp = logprior(xi)\n",
    "        logposterior.append(lp+ll)\n",
    "        logp.append(lp)\n",
    "        logl.append(ll)\n",
    "        \n",
    "        if (j+1)%100==0:\n",
    "            progressBar(time.time()-start,j+1,max_time,acc_ratio)\n",
    "        j+=1\n",
    "        \n",
    "    progressBar(max_time,j,max_time,acc_ratio)\n",
    "    \n",
    "    acc_ratio = acc_ratio/(j)\n",
    "    print('\\nMCMC algorithm terminated: ' + str(time.ctime()) + '. \\nRuntime = ' + str(time.time()-start) + '\\nSteps: ' + str(j))\n",
    "    print('Final loglikelihood: ',ll)\n",
    "    print('Acceptance ratio is ',acc_ratio)\n",
    "    \n",
    "    trajectory_plot(logposterior[1:],'figs/GWF_no_forward_model/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_logposterior')\n",
    "    trajectory_plot(logp[1:],'figs/GWF_no_forward_model/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_logprior')\n",
    "    trajectory_plot(logl[1:],'figs/GWF_no_forward_model/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_loglikelihood')\n",
    "    \n",
    "    for l in range(n_layer+1):\n",
    "        np.save('np_saved/GWF_no_forward_model/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_lastSample_w'+str(l)+'.npy',xi[0][l])\n",
    "        np.save('np_saved/GWF_no_forward_model/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_lastSample_b'+str(l)+'.npy',xi[1][l])\n",
    "    func_plot_log(xi,'figs/GWF_no_forward_model/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_lastSample')\n",
    "    \n",
    "    ESS(logposterior,'figs/GWF_no_forward_model/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_autocorr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROGRAMMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "MAIN PROGRAMME 1\n",
    "\n",
    "\"\"\"    \n",
    "\n",
    "# set maximal runtime\n",
    "t_max = 4*24*3600\n",
    "\n",
    "''' Initialise network network, see second block for detailed comments '''\n",
    "input_size = 2*dim\n",
    "output_size = 1\n",
    "n_layer = 1\n",
    "hidden_sizes = [100]\n",
    "hyps = str(hidden_sizes[0])\n",
    "for i in range(1,n_layer):\n",
    "    hyps = hyps+'_'+str(hidden_sizes[i])\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(hidden_sizes[-1], output_size))\n",
    "weights = []\n",
    "biases = []\n",
    "for l in range(n_layer+1):\n",
    "    weights.append(np.zeros(model[2*l].weight.shape))\n",
    "    biases.append(np.zeros(model[2*l].bias.shape))\n",
    "for l in range(n_layer+1):\n",
    "    model[2*l].weight = torch.nn.Parameter(torch.from_numpy(0*weights[l]).float(), requires_grad=False)\n",
    "    model[2*l].bias = torch.nn.Parameter(torch.from_numpy(0*biases[l]).float(), requires_grad=False)\n",
    "''' Initialise covariance operator, see prior block for detailed comments '''\n",
    "C = [[],[]]\n",
    "C_root = [[],[]]\n",
    "C_arr = np.ones(model[0].weight.shape)\n",
    "for t in range(hidden_sizes[0]):\n",
    "    for s in range(input_size):\n",
    "        C_arr[t][s] = sigma_w_sq[0]/np.power(t+1,alpha)\n",
    "C[0].append(C_arr)\n",
    "C_root[0].append(C_arr**(1/2))\n",
    "for l in range(1,n_layer):\n",
    "    C_arr = np.ones(model[2*l].weight.shape)\n",
    "    for t in range(hidden_sizes[l]):\n",
    "        for s in range(hidden_sizes[l-1]):\n",
    "            C_arr[t][s] = sigma_w_sq[l]/np.power(s+1,alpha)/np.power(t+1,alpha)\n",
    "    C[0].append(C_arr)\n",
    "    C_root[0].append(C_arr**(1/2))\n",
    "C_arr = np.ones(model[2*n_layer].weight.shape)   \n",
    "for t in range(output_size):\n",
    "    for s in range(hidden_sizes[n_layer-1]):\n",
    "        C_arr[t][s] = sigma_w_sq[n_layer]/np.power(s+1,alpha)\n",
    "C[0].append(C_arr)   \n",
    "C_root[0].append(C_arr**(1/2))\n",
    "C_arr = np.ones(model[0].bias.shape)\n",
    "for t in range(hidden_sizes[0]):\n",
    "    C_arr[t] = sigma_b_sq[0]/np.power(t+1,alpha)\n",
    "C[1].append(C_arr)\n",
    "C_root[1].append(C_arr**(1/2))\n",
    "for l in range(1,n_layer):\n",
    "    C_arr = np.ones(model[2*l].bias.shape)\n",
    "    for t in range(hidden_sizes[l]):\n",
    "        C_arr[t] = sigma_b_sq[l]/np.power(t+1,alpha)\n",
    "    C[1].append(C_arr)\n",
    "    C_root[1].append(C_arr**(1/2))\n",
    "C_arr = np.ones(model[2*n_layer].bias.shape)\n",
    "for t in range(output_size):\n",
    "    C_arr[t] = sigma_b_sq[n_layer]/np.power(t+1,alpha)\n",
    "C[1].append(C_arr)\n",
    "C_root[1].append(C_arr**(1/2))\n",
    "\n",
    "# Sample from the prior to see what a sample looks like\n",
    "xi = sample_prior()\n",
    "func_plot(xi,'figs/GWF_no_forward_model/NN_'+hyps+'_a_prior_sample')\n",
    "\n",
    "N_data = m**2\n",
    "data = np.load('GWF_data_all_u.npy')\n",
    "\n",
    "''' run pCN '''\n",
    "# np.random.seed(42)\n",
    "method = 'pCN'\n",
    "beta =  1/2500\n",
    "counts = np.zeros(2)\n",
    "try:\n",
    "    xi = [[],[]]\n",
    "    for l in range(n_layer+1):\n",
    "        xi[0].append(np.load('np_saved/GWF_no_forward_model/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_lastSample_w'+str(l)+'.npy'))\n",
    "        xi[1].append(np.load('np_saved/GWF_no_forward_model/NN_'+hyps+'_'+method+'_NData'+str(N_data)+'_lastSample_b'+str(l)+'.npy'))\n",
    "except FileNotFoundError:\n",
    "    print('Starting from close to 0')\n",
    "    xi = sample_prior(0.01)\n",
    "\n",
    "MCMC(xi,N_data,data,t_max) \n",
    "print('Counts: '+str(int(counts[0]))+' accepted prior moves, '+str(int(counts[1]))+' rejected ones.')  \n",
    "\n",
    "print('\\n\\n\\nSo far this code ran 25 full days.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
