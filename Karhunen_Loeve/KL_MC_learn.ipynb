{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import geom\n",
    "from copy import deepcopy as dc\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import numba\n",
    "\n",
    "N_a = 3                             # number of possible actions (actions are -1, 0, and 1)\n",
    "sigma = 0.1                         # noise\n",
    "dim = 2                             # dimensionality of the space (v: R^d --> R)\n",
    "obs_min = np.array([-1.2,-0.07])\n",
    "obs_max = np.array([ 0.6, 0.07])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "initialise KL\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "alpha = 2\n",
    "def eigenvalues_1():\n",
    "    ev_1 = np.zeros(2*N_trunc-2)\n",
    "    for i in range(1,N_trunc):\n",
    "        c_i = 1/((i+1)**2+(i+1)**2)**alpha\n",
    "        ev_1[2*i-2] = c_i\n",
    "        ev_1[2*i-1] = c_i\n",
    "    ev_1 = 20*ev_1*np.sqrt(2)/np.pi**2\n",
    "    return ev_1**2\n",
    "\n",
    "def eigenvalues_2():\n",
    "    ev_2 = np.zeros(4*N_trunc**2-4)\n",
    "    for i in range(1,N_trunc):\n",
    "        for j in range(1,N_trunc):\n",
    "            c_ij = 1/((i+1)**2+(j+1)**2)**alpha\n",
    "            ev_2[4*(i+N_trunc*j)-4] = c_ij\n",
    "            ev_2[4*(i+N_trunc*j)-3] = c_ij\n",
    "            ev_2[4*(i+N_trunc*j)-2] = c_ij\n",
    "            ev_2[4*(i+N_trunc*j)-1] = c_ij\n",
    "    ev_2 = 20*ev_2*np.sqrt(2)/np.pi**2\n",
    "    return ev_2**2\n",
    "\n",
    "def C_init():\n",
    "    C = np.zeros((4*N_trunc**2-4,dim,dim))\n",
    "    C_root = np.zeros((4*N_trunc**2-4,dim,dim))\n",
    "    \n",
    "    for j in range(dim):\n",
    "        for i_1 in range(1,N_trunc):\n",
    "            C[2*i_1-2,j,0] = ev_1[2*i_1-2]\n",
    "            C[2*i_1-1,j,0] = ev_1[2*i_1-1]\n",
    "            \n",
    "    for j in range(dim):\n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        C[4*(i_1+N_trunc*i_2)-4,j,k] = ev_2[4*(i_1+N_trunc*i_2)-4]\n",
    "                        C[4*(i_1+N_trunc*i_2)-3,j,k] = ev_2[4*(i_1+N_trunc*i_2)-3]\n",
    "                        C[4*(i_1+N_trunc*i_2)-2,j,k] = ev_2[4*(i_1+N_trunc*i_2)-2]\n",
    "                        C[4*(i_1+N_trunc*i_2)-1,j,k] = ev_2[4*(i_1+N_trunc*i_2)-1]\n",
    "    C_root = C**(1/2)\n",
    "    return C,C_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - PRIOR\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def sample_prior(c=1):\n",
    "    xi = np.zeros((4*N_trunc**2-4,dim,dim))\n",
    "    \n",
    "    for j in range(dim):\n",
    "        for i_1 in range(1,N_trunc):\n",
    "            xi[2*i_1-2,j,0] = C_root[2*i_1-2,j,0]*np.random.normal()\n",
    "            xi[2*i_1-1,j,0] = C_root[2*i_1-1,j,0]*np.random.normal()\n",
    "            \n",
    "    for j in range(dim):\n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        xi[4*(i_1+N_trunc*i_2)-4,j,k] = C_root[4*(i_1+N_trunc*i_2)-4,j,k]*np.random.normal()\n",
    "                        xi[4*(i_1+N_trunc*i_2)-3,j,k] = C_root[4*(i_1+N_trunc*i_2)-3,j,k]*np.random.normal()\n",
    "                        xi[4*(i_1+N_trunc*i_2)-2,j,k] = C_root[4*(i_1+N_trunc*i_2)-2,j,k]*np.random.normal()\n",
    "                        xi[4*(i_1+N_trunc*i_2)-1,j,k] = C_root[4*(i_1+N_trunc*i_2)-1,j,k]*np.random.normal()\n",
    "    return xi*c\n",
    "\n",
    "def logprior(xi):\n",
    "    logprior = 0\n",
    "    \n",
    "    for j in range(dim):\n",
    "        for i in range(1,N_trunc):\n",
    "            logprior += np.log(norm._pdf(xi[2*i-2,j,0]/C_root[2*i-2,j,0]))\n",
    "            logprior += np.log(norm._pdf(xi[2*i-1,j,0]/C_root[2*i-1,j,0]))\n",
    "    \n",
    "    for j in range(dim):\n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        logprior += np.log(norm._pdf(xi[4*(i_1+N_trunc*i_2)-4,j,k]/C_root[4*(i_1+N_trunc*i_2)-4,j,k]))\n",
    "                        logprior += np.log(norm._pdf(xi[4*(i_1+N_trunc*i_2)-3,j,k]/C_root[4*(i_1+N_trunc*i_2)-3,j,k]))\n",
    "                        logprior += np.log(norm._pdf(xi[4*(i_1+N_trunc*i_2)-2,j,k]/C_root[4*(i_1+N_trunc*i_2)-2,j,k]))\n",
    "                        logprior += np.log(norm._pdf(xi[4*(i_1+N_trunc*i_2)-1,j,k]/C_root[4*(i_1+N_trunc*i_2)-1,j,k]))\n",
    "                    \n",
    "    return logprior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - LIKELIHOOD \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "''' Function to integrate within likelihood '''\n",
    "def f(x,v_a):\n",
    "    value = norm._pdf((x-v_a[0])/sigma)/sigma\n",
    "    for i in range(1,N_a):\n",
    "        value = value*norm._cdf((x-v_a[i])/sigma)\n",
    "    return value\n",
    "\n",
    "def likelihood(xi,pair):\n",
    "    ''' Check where agent's action would take us '''\n",
    "    pos_curr = pair[0]\n",
    "    speed_curr = pair[1]\n",
    "    action = int(pair[2])\n",
    "    \n",
    "    data_state = pair[0:dim]\n",
    "    x = np.zeros((N_a,dim))\n",
    "    v = np.zeros(N_a)\n",
    "    for j in range(N_a):\n",
    "        env.state = data_state\n",
    "        x[j,:] = env.step(j)[0]\n",
    "        v[j] = u(xi,x[j,:])\n",
    "        \n",
    "    # sort v such that the first entry is the taken action\n",
    "    v_a = np.zeros(N_a)\n",
    "    if action!=0:\n",
    "        v_a[0] = v[action]\n",
    "        v_a[1:action+1] = v[0:action]\n",
    "        v_a[action+1:] = v[action+1:]\n",
    "    else:\n",
    "        v_a = v\n",
    "    \n",
    "    lklhd = quad(f,v_a[0]-3*sigma,v_a[0]+3*sigma,args=v_a,limit=200)[0]\n",
    "    return lklhd\n",
    "\n",
    "def loglikelihood(xi,data):\n",
    "    loglikelihood = 0\n",
    "    for j in range(data.shape[0]):\n",
    "        lh = likelihood(xi,data[j,:])\n",
    "        loglikelihood += np.log(lh)\n",
    "    return loglikelihood\n",
    "\n",
    "''' partial derivative du/dxi '''\n",
    "@numba.njit()\n",
    "def diff_u(x,shape):    \n",
    "    diff = np.zeros(shape)\n",
    "    for j in range(dim):\n",
    "        \n",
    "        ''' 1D terms '''\n",
    "        j_eval = np.pi*(x[j]-obs_min[j])/(obs_max[j]-obs_min[j])\n",
    "        for i in range(1,N_trunc):\n",
    "            c_j = 2/(obs_max[j]-obs_min[j])\n",
    "            diff[2*i-2,j,0] += c_j*np.cos(i*j_eval)\n",
    "            diff[2*i-1,j,0] += c_j*np.sin(i*j_eval)\n",
    "            \n",
    "        ''' 2D terms '''   \n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                j_eval = np.pi*(x[j]-obs_min[j])/(obs_max[j]-obs_min[j])\n",
    "                k_eval = np.pi*(x[k]-obs_min[k])/(obs_max[k]-obs_min[k])\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        c_jk = 4/(obs_max[j]-obs_min[j])/(obs_max[k]-obs_min[k])\n",
    "                        diff[4*(i_1+N_trunc*i_2)-4,j,k] += c_jk*np.cos(i_1*j_eval)*np.cos(i_2*k_eval)\n",
    "                        diff[4*(i_1+N_trunc*i_2)-3,j,k] += c_jk*np.cos(i_1*j_eval)*np.sin(i_2*k_eval)\n",
    "                        diff[4*(i_1+N_trunc*i_2)-2,j,k] += c_jk*np.sin(i_1*j_eval)*np.cos(i_2*k_eval)\n",
    "                        diff[4*(i_1+N_trunc*i_2)-1,j,k] += c_jk*np.sin(i_1*j_eval)*np.sin(i_2*k_eval)\n",
    "    return diff\n",
    "\n",
    "''' function which is integrated in likelihood gradient '''\n",
    "def f_grad(t,args):\n",
    "    v_a = args[0]\n",
    "    j = args[1]\n",
    "    if j==0:\n",
    "        value = (t-v_a[0])/(sigma**2)*norm._pdf((t-v_a[0])/sigma)/sigma\n",
    "    else:\n",
    "        value = -norm._pdf((v_a[0]-v_a[j])/(np.sqrt(2)*sigma))/(np.sqrt(2)*sigma)*norm._pdf((t-(v_a[0]+v_a[j])/2)/(sigma/np.sqrt(2)))/(sigma/np.sqrt(2))\n",
    "    for i in range(1,N_a):\n",
    "        if i!=j:\n",
    "            value = value*norm._cdf((t-v_a[i])/sigma)\n",
    "    return value\n",
    "\n",
    "''' partial derivative dl/dv '''\n",
    "def grad_ll(v_a,j):\n",
    "    if j==0:\n",
    "        return quad(f_grad,v_a[0]-3*sigma,v_a[0]+3*sigma,args=[v_a,j],limit=200)[0]\n",
    "    else:\n",
    "        return quad(f_grad,(v_a[0]+v_a[j])/2-3*(sigma/np.sqrt(2)),(v_a[0]+v_a[j])/2+3*(sigma/np.sqrt(2)),args=[v_a,j],limit=200)[0]\n",
    "\n",
    "''' partial derivative dl/dxi'''\n",
    "def diff_ll(xi,data):\n",
    "    diff = np.zeros(xi.shape)\n",
    "    \n",
    "    x = np.zeros((N_a,dim))\n",
    "    v = np.zeros(N_a)\n",
    "    x_a = np.zeros((N_a,dim))\n",
    "    v_a = np.zeros(N_a)\n",
    "    grad_a = np.zeros(N_a)\n",
    "    data_state = np.zeros(dim)\n",
    "    \n",
    "    ''' Iterate through all or a subset of the data points, and compute the respective gradients '''\n",
    "    if stochastic_gradients and unadjusted:\n",
    "        range_i = random.sample(range(data.shape[0]),10)\n",
    "    else:\n",
    "        range_i = range(data.shape[0])\n",
    "    for i in range_i:\n",
    "        lh = likelihood(xi,data[i,:])\n",
    "        data_state = data[i,0:dim]\n",
    "        data_action = int(data[i,-1])\n",
    "        \n",
    "        ''' compute locations the actions would take us to and the values of the value function at those points '''\n",
    "        for j in range(N_a):\n",
    "            env.state = data_state\n",
    "            x[j,:] = env.step(j)[0]\n",
    "            v[j] = u(xi,x[j,:])\n",
    "        \n",
    "        ''' sort v and x such that the first entry is the taken action '''\n",
    "        if data_action!=0:\n",
    "            v_a[0] = v[data_action]\n",
    "            v_a[1:data_action+1] = v[0:data_action]\n",
    "            v_a[data_action+1:] = v[data_action+1:]\n",
    "            x_a[0,:] = x[data_action,:]\n",
    "            x_a[1:data_action+1,:] = x[0:data_action,:]\n",
    "            x_a[data_action+1:,:] = x[data_action+1:,:]\n",
    "        else:\n",
    "            v_a = v\n",
    "            x_a = x\n",
    "            \n",
    "        ''' Calculate gradient at the v_i the action i would give us '''\n",
    "        for j in range(N_a):\n",
    "            grad_a[j] = grad_ll(v_a,j)/lh\n",
    "        mean_grad = np.mean(grad_a)\n",
    "        grad_a -= mean_grad\n",
    "            \n",
    "        for j in range(N_a):\n",
    "            diff += grad_a[j]*diff_u(x_a[j,:],xi.shape)\n",
    "            \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - VALUE FUNCTION AND POLICIES\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "''' u(xi,x), which evaluates the function u with coefficients xi at x=(pos,speed) --- new, complicated, but fast version '''\n",
    "@numba.njit()\n",
    "def u(xi,x):\n",
    "    u_sum = 0\n",
    "    for j in range(dim):\n",
    "        \n",
    "        ''' 1D terms '''\n",
    "        j_eval = np.pi*(x[j]-obs_min[j])/(obs_max[j]-obs_min[j])\n",
    "        for i in range(1,N_trunc):\n",
    "            c_j = 2/(obs_max[j]-obs_min[j])\n",
    "            u_sum += c_j*xi[2*i-2,j,0]*np.cos(i*j_eval)\n",
    "            u_sum += c_j*xi[2*i-1,j,0]*np.sin(i*j_eval)\n",
    "            \n",
    "        ''' 2D terms '''   \n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                j_eval = np.pi*(x[j]-obs_min[j])/(obs_max[j]-obs_min[j])\n",
    "                k_eval = np.pi*(x[k]-obs_min[k])/(obs_max[k]-obs_min[k])\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        c_jk = 4/(obs_max[j]-obs_min[j])/(obs_max[k]-obs_min[k])\n",
    "                        u_sum += c_jk*xi[4*(i_1+N_trunc*i_2)-4,j,k]*np.cos(i_1*j_eval)*np.cos(i_2*k_eval)\n",
    "                        u_sum += c_jk*xi[4*(i_1+N_trunc*i_2)-3,j,k]*np.cos(i_1*j_eval)*np.sin(i_2*k_eval)\n",
    "                        u_sum += c_jk*xi[4*(i_1+N_trunc*i_2)-2,j,k]*np.sin(i_1*j_eval)*np.cos(i_2*k_eval)\n",
    "                        u_sum += c_jk*xi[4*(i_1+N_trunc*i_2)-1,j,k]*np.sin(i_1*j_eval)*np.sin(i_2*k_eval)\n",
    "    return u_sum\n",
    "\n",
    "''' Policy from \"Reinforcement Learning: Theory and {Python} Implementation\" '''\n",
    "def policy(position,velocity):\n",
    "        lb = min(-0.09 * (position + 0.25) ** 2 + 0.03,\n",
    "                0.3 * (position + 0.9) ** 4 - 0.008)\n",
    "        ub = -0.07 * (position + 0.38) ** 2 + 0.07\n",
    "        if lb < velocity < ub:\n",
    "            action = 2 # push right\n",
    "        else:\n",
    "            action = 0 # push left\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - ANALYTICS\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "''' Progress bar to know how much longer one has to wait '''\n",
    "def progressBar(t,value, t_max, acceptances, bar_length=40):\n",
    "    percent = float(t) / t_max\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    sys.stdout.write(\"\\rIteration: {0}    Acceptance ratio: {1}    Percent: [{2}] {3}%  \".format(value,round(acceptances/value,3),arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()     \n",
    "        \n",
    "''' Plotting a value function '''    \n",
    "def func_plot(xi,name):\n",
    "    x = np.arange(-1.2,0.6,0.02)\n",
    "    y = np.arange(-0.07,0.07,0.002)\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    Z = np.zeros(X.shape)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            x=np.zeros(dim)\n",
    "            x[0]=X[i,j]\n",
    "            x[1]=Y[i,j]\n",
    "            Z[i,j] = u(xi,x)\n",
    "            \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.RdBu,linewidth=0, antialiased=False)\n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "    ax.set_xlabel('x-axis')\n",
    "    ax.set_ylabel('y-axis')\n",
    "    ax.set_zlabel('z-axis')\n",
    "    ax.view_init(elev=25, azim=-120)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    fig.savefig(name + '.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "    \n",
    "''' Plot a trajectory '''  \n",
    "def trajectory_plot(xi,name):\n",
    "    x = np.arange(len(xi))\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x,xi)\n",
    "    fig.savefig(name + '.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "''' Compute the autocorrelations '''    \n",
    "def autocorr(x,lags):\n",
    "    mean=np.mean(x)\n",
    "    var=np.var(x)\n",
    "    xp=x-mean\n",
    "    corr=[1. if l==0 else np.sum(xp[l:]*xp[:-l])/len(x)/var for l in lags]\n",
    "    return np.array(corr)\n",
    "\n",
    "''' Calculate the Effective Sample Size, assumes algorithm already burned in '''\n",
    "def ESS(logposterior,name):\n",
    "    fig, ax = plt.subplots()\n",
    "    N = len(logposterior)\n",
    "    ax.stem(autocorr(logposterior, range(int(N*0.1))),use_line_collection=True) \n",
    "    ESS = N/(1+2*sum(autocorr(logposterior, range(int(N*0.1)))))\n",
    "    print('\\nEffective Sample Size:', round(ESS))\n",
    "    print('Samples required to generate 1 independent sample:', round(N/ESS,2))\n",
    "    fig.savefig(name + '.png', bbox_inches='tight')\n",
    "    plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Uncertainty Quantification Initialisation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "x_test = np.load('MC_x_test.npy')\n",
    "a_test = np.asarray(np.load('MC_a_test.npy'),dtype=int)\n",
    "    \n",
    "v_test = [[],[],[],[],[]]\n",
    "for j in range(5):\n",
    "    for i in range(N_a):\n",
    "        v_test[j].append([])\n",
    "\n",
    "def test_value_fn(xi):\n",
    "    for j in range(5):\n",
    "        ''' Evaluate value function at test points '''\n",
    "        for i in range(N_a):\n",
    "            v = u(xi,x_test[i,:,j])\n",
    "            v_test[j][i].append(v)\n",
    "        ''' substract value at optimal test point for normalisation purposes'''\n",
    "        for i in range(N_a):\n",
    "            if i!=a_test[j]:\n",
    "                v_test[j][i][-1]=v_test[j][i][-1]-v_test[j][a_test[j]][-1]\n",
    "        v_test[j][a_test[j]][-1] = 0\n",
    "        \n",
    "def boxplot_value_fn():\n",
    "    global v_test\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('UQ of relative value function evaluation')\n",
    "    ax.boxplot(v_test[0], positions = [0,1,2])\n",
    "    ax.boxplot(v_test[1], positions = [4,5,6])\n",
    "    ax.boxplot(v_test[2], positions = [8,9,10])\n",
    "    ax.boxplot(v_test[3], positions = [12,13,14])\n",
    "    ax.boxplot(v_test[4], positions = [16,17,18])\n",
    "    ax.set_xticklabels(['L','0','R','L','0','R','L','0','R','L','0','R','L','0','R'])\n",
    "\n",
    "    fig.savefig('figs/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_UQ.pdf', dpi=300)\n",
    "    plt.close(fig) \n",
    "    \n",
    "    v_test = [[],[],[],[],[]]\n",
    "    for j in range(5):\n",
    "        for i in range(N_a):\n",
    "            v_test[j].append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - MCMC (pCN/pCNL)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def acceptance_prop(xi_u, xi_v,data,ll_u,diff_u=False):\n",
    "    accept_prop = -ll_u\n",
    "    ll_v = 0\n",
    "        \n",
    "    for j in range(data.shape[0]):\n",
    "        lh = likelihood(xi_v,data[j,:])\n",
    "        ll_v += np.log(lh)\n",
    "    accept_prop += ll_v\n",
    "        \n",
    "    ''' Only pCNL (has extra terms) '''\n",
    "    if method=='pCNL':\n",
    "        accept_prop += -np.sum((xi_v-xi_u)*diff_u)/2 - delta*np.sum((xi_u+xi_v)*diff_u)/4 + delta*np.linalg.norm(diff_u*C_root)**2/4\n",
    "        diff_v = diff_ll(xi_v,data)\n",
    "        accept_prop -= -np.sum((xi_u-xi_v)*diff_v)/2 - delta*np.sum((xi_v+xi_u)*diff_v)/4 + delta*np.linalg.norm(diff_v*C_root)**2/4\n",
    "        return min(1, np.exp(accept_prop)),ll_v,diff_v\n",
    "    else:\n",
    "        return min(1, np.exp(accept_prop)),ll_v\n",
    "    \n",
    "def propose(xi,diff=False):\n",
    "    if method=='pCNL':\n",
    "        proposal = ((2-delta)*xi + 2*delta*C*diff + np.sqrt(8*delta)*sample_prior())/(2+delta)     \n",
    "    else:\n",
    "        proposal = np.sqrt(1-beta*beta)*xi+beta*sample_prior()\n",
    "    return proposal\n",
    "\n",
    "def MCMC(xi,N_data,data,max_time):   \n",
    "    print('\\nMCMC algorithm ('+method + ', N_trunc=' + str(N_trunc) + ', N_data=' + str(N_data) + ', ' + str(max_time) + ' seconds) was started: ' + str(time.ctime()))\n",
    "        \n",
    "    acc_ratio = 0\n",
    "    logposterior = []\n",
    "    logp = []\n",
    "    logl = []\n",
    "    \n",
    "    ''' Initialise likelihood and gradient '''  \n",
    "    ll = loglikelihood(xi,data)\n",
    "    print('Initial loglikelihood: ',ll)\n",
    "    if method=='CNL' or method=='pCNL':\n",
    "        diff = diff_ll(xi,data)\n",
    "        func_plot(diff,'figs/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_diff')\n",
    "    \n",
    "    ''' Run MCMC '''\n",
    "    start = time.time() \n",
    "    j = 0\n",
    "    it = 0\n",
    "    while(time.time()-start<max_time):\n",
    "        \n",
    "        ''' Propose and calculate acceptance probability '''\n",
    "        if method=='CNL' or method=='pCNL':\n",
    "            xi_proposal = propose(xi,diff)  \n",
    "            a,ll_proposal,diff_proposal = acceptance_prop(xi,xi_proposal,data,ll,diff)\n",
    "        else:\n",
    "            xi_proposal = propose(xi)  \n",
    "            a,ll_proposal = acceptance_prop(xi,xi_proposal,data,ll)\n",
    "        \n",
    "        ''' Accept or reject proposal '''\n",
    "        uni = np.random.uniform()\n",
    "        if uni < a or unadjusted:\n",
    "            if method=='CNL' or method=='pCNL':\n",
    "                diff = diff_proposal\n",
    "            xi = xi_proposal    \n",
    "            ll = ll_proposal\n",
    "            acc_ratio = acc_ratio + 1\n",
    "            \n",
    "\n",
    "        ''' prior, likelihood, and posterior traceplots are appended '''\n",
    "        lp = logprior(xi)\n",
    "        logposterior.append(lp+ll)\n",
    "        logp.append(lp)\n",
    "        logl.append(ll)\n",
    "        \n",
    "        if prior_compare and j%10==0:\n",
    "            ''' store value function evaluations for uncertainty estimates '''\n",
    "            test_value_fn(xi)\n",
    "        elif policy_compare and (time.time()-start)>it*t_max/1000 and it<1000:\n",
    "            ''' store sample for future use '''\n",
    "            np.save('np_saved/MC/samples_policy_learning/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_sampleNo'+str(it)+'.npy',xi)\n",
    "            it += 1\n",
    "        \n",
    "        if (j+1)%100==0:\n",
    "            progressBar(time.time()-start,j+1,max_time,acc_ratio)\n",
    "        j+=1\n",
    "        \n",
    "    progressBar(max_time,j,max_time,acc_ratio)\n",
    "    \n",
    "    acc_ratio = acc_ratio/(j)\n",
    "    print('\\nMCMC algorithm terminated: ' + str(time.ctime()) + '. \\nRuntime = ' + str(time.time()-start))\n",
    "    print('Final loglikelihood: ',ll)\n",
    "    print('Acceptance ratio is ',acc_ratio)\n",
    "    \n",
    "    trajectory_plot(logposterior[1:],'figs/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_logposterior')\n",
    "    trajectory_plot(logp[1:],'figs/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_logprior')\n",
    "    trajectory_plot(logl[1:],'figs/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_loglikelihood')\n",
    "    if prior_compare:\n",
    "        boxplot_value_fn()\n",
    "    np.save('np_saved/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample.npy',xi)\n",
    "    func_plot(xi,'figs/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample')\n",
    "    \n",
    "    ESS(logposterior,'figs/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_autocorr')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROGRAMMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MCMC algorithm (pCNL, N_trunc=70, N_data=50, 120 seconds) was started: Sat Jul 18 16:36:06 2020\n",
      "Initial loglikelihood:  -30.015746202235338\n",
      "Iteration: 283    Acceptance ratio: 0.777    Percent: [--------------------------------------->] 100%  \n",
      "MCMC algorithm terminated: Sat Jul 18 16:38:08 2020. \n",
      "Runtime = 120.38629126548767\n",
      "Final loglikelihood:  -19.787930200522254\n",
      "Acceptance ratio is  0.7773851590106007\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "MAIN PROGRAMME 1 - compare NN prior to KL prior (large number of parameters)\n",
    "\n",
    "\"\"\"       \n",
    "\n",
    "prior_compare = True\n",
    "policy_compare = False\n",
    "\n",
    "# set maximal runtime\n",
    "t_max = 3600*10\n",
    "\n",
    "N_trunc = 70 # make sure to restart the kernel and recompile the numba compiled code\n",
    "ev_1 = eigenvalues_1()\n",
    "ev_2 = eigenvalues_2()\n",
    "C,C_root = C_init()\n",
    "\n",
    "# Sample from the prior to see what a sample looks like\n",
    "xi = sample_prior()\n",
    "func_plot(xi,'figs/MC/KL_'+str(N_trunc)+'_a_prior_sample')\n",
    "\n",
    "# Create environment \n",
    "env = gym.make('MountainCar-v0')\n",
    "env = env.unwrapped\n",
    "data = np.load('MC_data.npy')\n",
    "N_data = 50 \n",
    "\n",
    "''' run pCN '''\n",
    "method = 'pCN'\n",
    "stochastic_gradients = False\n",
    "unadjusted = False\n",
    "beta =  1/2.1\n",
    "try:\n",
    "    xi = np.load('np_saved/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample.npy')\n",
    "except FileNotFoundError:\n",
    "    print('Starting from close to 0')\n",
    "    xi = sample_prior(0.1)\n",
    "MCMC(xi,N_data,data[0:N_data,:],t_max) \n",
    "                                          \n",
    "env.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MCMC algorithm (pCNL, N_trunc=7, N_data=50, 36000 seconds) was started: Sat Jul 18 22:51:54 2020\n",
      "Initial loglikelihood:  -23.453563879154917\n",
      "Iteration: 185040    Acceptance ratio: 0.667    Percent: [--------------------------------------->] 100%  \n",
      "MCMC algorithm terminated: Sun Jul 19 08:51:56 2020. \n",
      "Runtime = 36000.08349490166\n",
      "Final loglikelihood:  -24.122343331108585\n",
      "Acceptance ratio is  0.6670395590142671\n",
      "\n",
      "Effective Sample Size: 8196.0\n",
      "Samples required to generate 1 independent sample: 22.58\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "MAIN PROGRAMME 2 - LEARN policy, and store mean for future use (small number of parameters)\n",
    "\n",
    "\"\"\"    \n",
    "\n",
    "prior_compare = False\n",
    "policy_compare = True\n",
    "\n",
    "# set maximal runtime\n",
    "t_max = 3600*10\n",
    "\n",
    "N_trunc = 7 # make sure to restart the kernel and recompile the numba compiled code\n",
    "ev_1 = eigenvalues_1()\n",
    "ev_2 = eigenvalues_2()\n",
    "C,C_root = C_init()\n",
    "\n",
    "# Sample from the prior to see what a sample looks like\n",
    "xi = sample_prior()\n",
    "func_plot(xi,'figs/MC/KL_'+str(N_trunc)+'_a_prior_sample')\n",
    "\n",
    "# Create environment \n",
    "env = gym.make('MountainCar-v0')\n",
    "env = env.unwrapped\n",
    "data = np.load('MC_data.npy')\n",
    "N_data = 50\n",
    "\n",
    "\n",
    "''' run pCN '''\n",
    "method = 'pCN'\n",
    "stochastic_gradients = False\n",
    "unadjusted = False\n",
    "beta =  1/2.1\n",
    "try:\n",
    "    xi = np.load('np_saved/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample.npy')\n",
    "except FileNotFoundError:\n",
    "    print('Starting from close to 0')\n",
    "    xi = sample_prior(0.1)\n",
    "MCMC(xi,N_data,data[0:N_data,:],t_max) \n",
    "\n",
    "\n",
    "''' run pCNL '''\n",
    "method = 'pCNL'\n",
    "stochastic_gradients = False # if true then unadjusted needs to be true too\n",
    "unadjusted = False\n",
    "delta = 1/18\n",
    "try:\n",
    "    xi = np.load('np_saved/MC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample.npy')\n",
    "except FileNotFoundError:\n",
    "    print('\\nStarting from close to 0')\n",
    "    xi = sample_prior(0.1)\n",
    "MCMC(xi,N_data,data[0:N_data,:],t_max) \n",
    "                                          \n",
    "env.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
