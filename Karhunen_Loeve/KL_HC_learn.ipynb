{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/torbensell/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/torbensell/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/torbensell/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/torbensell/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/torbensell/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/torbensell/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import time, gym, sys\n",
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import geom\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "import matplotlib.pyplot as plt\n",
    "import homework.hw1.load_policy as load_policy\n",
    "import homework.hw1.tf_util as tf_util\n",
    "import tensorflow as tf\n",
    "from copy import deepcopy as dc\n",
    "import numba\n",
    "\n",
    "sigma = 0.1\n",
    "\n",
    "dim = 17\n",
    "dim_act = 6\n",
    "obs_min = np.array([-0.25,-0.8 ,-0.7 ,-0.7,-0.65,-0.75,-0.95,-0.6 ,-1.5,-3.1,-7.1,-20,-24,-27,-27,-30,-20])\n",
    "obs_max = np.array([ 0.4 , 1.65, 0.95, 0.9, 0.95, 0.95, 1.1 , 0.75, 8  , 3.4, 7  , 19, 25, 22, 25, 32, 26])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "initialise KL\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "alpha = 2\n",
    "def eigenvalues_1():\n",
    "    ev_1 = np.zeros(2*N_trunc-2)\n",
    "    for i in range(1,N_trunc):\n",
    "        c_i = 1/((i+1)**2+(i+1)**2)**alpha\n",
    "        ev_1[2*i-2] = c_i\n",
    "        ev_1[2*i-1] = c_i\n",
    "    ev_1 = 4*ev_1\n",
    "    return ev_1**2\n",
    "\n",
    "def eigenvalues_2():\n",
    "    ev_2 = np.zeros(4*N_trunc**2-4)\n",
    "    for i in range(1,N_trunc):\n",
    "        for j in range(1,N_trunc):\n",
    "            c_ij = 1/((i+1)**2+(j+1)**2)**alpha\n",
    "            ev_2[4*(i+N_trunc*j)-4] = c_ij\n",
    "            ev_2[4*(i+N_trunc*j)-3] = c_ij\n",
    "            ev_2[4*(i+N_trunc*j)-2] = c_ij\n",
    "            ev_2[4*(i+N_trunc*j)-1] = c_ij\n",
    "    ev_2 = 4*ev_2\n",
    "    return ev_2**2\n",
    "\n",
    "def C_init():\n",
    "    C = np.zeros((4*N_trunc**2-4,dim,dim))\n",
    "    C_root = np.zeros((4*N_trunc**2-4,dim,dim))\n",
    "    \n",
    "    for j in range(dim):\n",
    "        for i_1 in range(1,N_trunc):\n",
    "            C[2*i_1-2,j,0] = ev_1[2*i_1-2]\n",
    "            C[2*i_1-1,j,0] = ev_1[2*i_1-1]\n",
    "            \n",
    "    for j in range(dim):\n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        C[4*(i_1+N_trunc*i_2)-4,j,k] = ev_2[4*(i_1+N_trunc*i_2)-4]\n",
    "                        C[4*(i_1+N_trunc*i_2)-3,j,k] = ev_2[4*(i_1+N_trunc*i_2)-3]\n",
    "                        C[4*(i_1+N_trunc*i_2)-2,j,k] = ev_2[4*(i_1+N_trunc*i_2)-2]\n",
    "                        C[4*(i_1+N_trunc*i_2)-1,j,k] = ev_2[4*(i_1+N_trunc*i_2)-1]\n",
    "    C_root = C**(1/2)\n",
    "    return C,C_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "INITIALISE ACTION AND OBSERVATION SPACE\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "actions = []\n",
    "actions_matrix = np.load('HC_actions.npy')\n",
    "N_a = 8\n",
    "for i in range(N_a):\n",
    "    actions.append(actions_matrix[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - PRIOR\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def sample_prior(c=1):\n",
    "    xi = np.zeros((4*N_trunc**2-4,dim,dim))\n",
    "    \n",
    "    for j in range(dim):\n",
    "        for i_1 in range(1,N_trunc):\n",
    "            xi[2*i_1-2,j,0] = C_root[2*i_1-2,j,0]*np.random.normal()\n",
    "            xi[2*i_1-1,j,0] = C_root[2*i_1-1,j,0]*np.random.normal()\n",
    "            \n",
    "    for j in range(dim):\n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        xi[4*(i_1+N_trunc*i_2)-4,j,k] = C_root[4*(i_1+N_trunc*i_2)-4,j,k]*np.random.normal()\n",
    "                        xi[4*(i_1+N_trunc*i_2)-3,j,k] = C_root[4*(i_1+N_trunc*i_2)-3,j,k]*np.random.normal()\n",
    "                        xi[4*(i_1+N_trunc*i_2)-2,j,k] = C_root[4*(i_1+N_trunc*i_2)-2,j,k]*np.random.normal()\n",
    "                        xi[4*(i_1+N_trunc*i_2)-1,j,k] = C_root[4*(i_1+N_trunc*i_2)-1,j,k]*np.random.normal()\n",
    "    return xi*c\n",
    "\n",
    "def logprior(xi):\n",
    "    logprior = 0\n",
    "    \n",
    "    for j in range(dim):\n",
    "        for i in range(1,N_trunc):\n",
    "            logprior += np.log(norm._pdf(xi[2*i-2,j,0]/C_root[2*i-2,j,0]))\n",
    "            logprior += np.log(norm._pdf(xi[2*i-1,j,0]/C_root[2*i-1,j,0]))\n",
    "    \n",
    "    for j in range(dim):\n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        logprior += np.log(norm._pdf(xi[4*(i_1+N_trunc*i_2)-4,j,k]/C_root[4*(i_1+N_trunc*i_2)-4,j,k]))\n",
    "                        logprior += np.log(norm._pdf(xi[4*(i_1+N_trunc*i_2)-3,j,k]/C_root[4*(i_1+N_trunc*i_2)-3,j,k]))\n",
    "                        logprior += np.log(norm._pdf(xi[4*(i_1+N_trunc*i_2)-2,j,k]/C_root[4*(i_1+N_trunc*i_2)-2,j,k]))\n",
    "                        logprior += np.log(norm._pdf(xi[4*(i_1+N_trunc*i_2)-1,j,k]/C_root[4*(i_1+N_trunc*i_2)-1,j,k]))\n",
    "                    \n",
    "    return logprior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - LIKELIHOOD \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "''' Function to integrate within likelihood '''\n",
    "def f(x,v_a):\n",
    "    value = norm._pdf((x-v_a[0])/sigma)/sigma\n",
    "    for i in range(1,N_a):\n",
    "        value = value*norm._cdf((x-v_a[i])/sigma)\n",
    "    return value\n",
    "\n",
    "def likelihood(xi,pair):\n",
    "    poss = pair[0:8]\n",
    "    vels = pair[8:17]\n",
    "    action = int(pair[17])\n",
    "    poss = np.insert(poss,0,0)\n",
    "    \n",
    "    ''' Check where all actions would take us '''\n",
    "    x = np.zeros((N_a,dim))\n",
    "    v = np.zeros(N_a)\n",
    "    for j in range(N_a):\n",
    "        env.set_state(poss, vels)\n",
    "        x[j,:] = env.step(actions[j])[0]\n",
    "        v[j] = u(xi,x[j,:])\n",
    "        \n",
    "    ''' Sort v such that the first entry is the taken action '''\n",
    "    v_a = np.zeros(N_a)\n",
    "    if action!=0:\n",
    "        v_a[0] = v[action]\n",
    "        v_a[1:action+1] = v[0:action]\n",
    "        v_a[action+1:] = v[action+1:]\n",
    "    else:\n",
    "        v_a = v\n",
    "            \n",
    "    ''' Integrate over pdf of chosen action and cdf of other actions '''\n",
    "    lklhd = quad(f,v_a[0]-3*sigma,v_a[0]+3*sigma,args=v_a,limit=500)[0]\n",
    "    return lklhd\n",
    "\n",
    "def loglikelihood(xi,data):\n",
    "    loglikelihood = 0\n",
    "    for j in range(data.shape[0]):\n",
    "        loglikelihood += np.log(likelihood(xi,data[j,:]))\n",
    "    return loglikelihood\n",
    "\n",
    "''' partial derivative du/dxi '''\n",
    "@numba.njit()\n",
    "def diff_u(x,shape):    \n",
    "    diff = np.zeros(shape)\n",
    "    for j in range(dim):\n",
    "        \n",
    "        ''' 1D terms '''\n",
    "        j_eval = np.pi*(x[j]-obs_min[j])/(obs_max[j]-obs_min[j])\n",
    "        for i in range(1,N_trunc):\n",
    "            c_j = 2/(obs_max[j]-obs_min[j])\n",
    "            diff[2*i-2,j,0] += c_j*np.cos(i*j_eval)\n",
    "            diff[2*i-1,j,0] += c_j*np.sin(i*j_eval)\n",
    "            \n",
    "        ''' 2D terms '''   \n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                j_eval = np.pi*(x[j]-obs_min[j])/(obs_max[j]-obs_min[j])\n",
    "                k_eval = np.pi*(x[k]-obs_min[k])/(obs_max[k]-obs_min[k])\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        c_jk = 4/(obs_max[j]-obs_min[j])/(obs_max[k]-obs_min[k])\n",
    "                        diff[4*(i_1+N_trunc*i_2)-4,j,k] += c_jk*np.cos(i_1*j_eval)*np.cos(i_2*k_eval)\n",
    "                        diff[4*(i_1+N_trunc*i_2)-3,j,k] += c_jk*np.cos(i_1*j_eval)*np.sin(i_2*k_eval)\n",
    "                        diff[4*(i_1+N_trunc*i_2)-2,j,k] += c_jk*np.sin(i_1*j_eval)*np.cos(i_2*k_eval)\n",
    "                        diff[4*(i_1+N_trunc*i_2)-1,j,k] += c_jk*np.sin(i_1*j_eval)*np.sin(i_2*k_eval)\n",
    "    return diff\n",
    "\n",
    "''' function which is integrated in likelihood gradient '''\n",
    "def f_grad(t,args):\n",
    "    v_a = args[0]\n",
    "    j = args[1]\n",
    "    if j==0:\n",
    "        value = (t-v_a[0])/(sigma**2)*norm._pdf((t-v_a[0])/sigma)/sigma\n",
    "    else:\n",
    "        value = -norm._pdf((v_a[0]-v_a[j])/(np.sqrt(2)*sigma))/(np.sqrt(2)*sigma)*norm._pdf((t-(v_a[0]+v_a[j])/2)/(sigma/np.sqrt(2)))/(sigma/np.sqrt(2))\n",
    "    for i in range(1,N_a):\n",
    "        if i!=j:\n",
    "            value = value*norm._cdf((t-v_a[i])/sigma)\n",
    "    return value\n",
    "\n",
    "''' partial derivative dl/dv '''\n",
    "def grad_ll(v_a,j):\n",
    "    if j==0:\n",
    "        return quad(f_grad,v_a[0]-3*sigma,v_a[0]+3*sigma,args=[v_a,j],limit=500)[0]\n",
    "    else:\n",
    "        return quad(f_grad,(v_a[0]+v_a[j])/2-3*sigma,(v_a[0]+v_a[j])/2+3*sigma,args=[v_a,j],limit=500)[0]\n",
    "\n",
    "    \n",
    "def diff_ll(xi,data):\n",
    "    diff = np.zeros(xi.shape)\n",
    "        \n",
    "    x = np.zeros((N_a,dim))\n",
    "    v = np.zeros(N_a)\n",
    "    x_a = np.zeros((N_a,dim))\n",
    "    v_a = np.zeros(N_a)\n",
    "    grad_a = np.zeros(N_a)\n",
    "    data_state = np.zeros(dim)\n",
    "    \n",
    "    ''' Iterate through all or a subset of the data points, and compute the respective gradients '''\n",
    "    if stochastic_gradients and unadjusted:\n",
    "        range_i = random.sample(range(data.shape[0]),10)\n",
    "    else:\n",
    "        range_i = range(data.shape[0])\n",
    "    for i in range_i:\n",
    "        lh = likelihood(xi,data[i,:])\n",
    "        data_poss = data[i,0:8]\n",
    "        data_vels = data[i,8:17]\n",
    "        data_poss = np.insert(data_poss,0,0)\n",
    "        data_action = int(data[i,-1])\n",
    "        \n",
    "        for j in range(N_a):\n",
    "            env.set_state(data_poss, data_vels)\n",
    "            x[j,:] = env.step(j)[0]\n",
    "            v[j] = u(xi,x[j,:])\n",
    "        \n",
    "        # sort v and x such that the first entry is the taken action\n",
    "        if data_action!=0:\n",
    "            v_a[0] = v[data_action]\n",
    "            v_a[1:data_action+1] = v[0:data_action]\n",
    "            v_a[data_action+1:] = v[data_action+1:]\n",
    "            x_a[0,:] = x[data_action,:]\n",
    "            x_a[1:data_action+1,:] = x[0:data_action,:]\n",
    "            x_a[data_action+1:,:] = x[data_action+1:,:]\n",
    "        else:\n",
    "            v_a = v\n",
    "            x_a = x\n",
    "            \n",
    "        for j in range(N_a):\n",
    "            grad_a[j] = grad_ll(v_a,j)/lh\n",
    "        mean_grad = np.mean(grad_a)\n",
    "        grad_a -= mean_grad\n",
    "            \n",
    "        for j in range(N_a):\n",
    "            diff += grad_a[j]*diff_u(x_a[j,:],xi.shape)\n",
    "            \n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading and building expert policy\n",
      "obs (1, 17) (1, 17)\n",
      "loaded and built\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - VALUE FUNCTION AND POLICIES\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "''' u(xi,x), which evaluates the function u with coefficients xi at x, fast version '''\n",
    "@numba.njit()\n",
    "def u(xi,x):\n",
    "    u_sum = 0\n",
    "    for j in range(dim):\n",
    "        \n",
    "        ''' 1D terms '''\n",
    "        j_eval = np.pi*(x[j]-obs_min[j])/(obs_max[j]-obs_min[j])\n",
    "        for i in range(1,N_trunc):\n",
    "            c_j = 2/(obs_max[j]-obs_min[j])\n",
    "            u_sum += c_j*xi[2*i-2,j,0]*np.cos(i*j_eval)\n",
    "            u_sum += c_j*xi[2*i-1,j,0]*np.sin(i*j_eval)\n",
    "            \n",
    "        ''' 2D terms '''   \n",
    "        for k in range(dim):\n",
    "            if k>j:\n",
    "                j_eval = np.pi*(x[j]-obs_min[j])/(obs_max[j]-obs_min[j])\n",
    "                k_eval = np.pi*(x[k]-obs_min[k])/(obs_max[k]-obs_min[k])\n",
    "                for i_1 in range(1,N_trunc):\n",
    "                    for i_2 in range(1,N_trunc):\n",
    "                        c_jk = 4/(obs_max[j]-obs_min[j])/(obs_max[k]-obs_min[k])\n",
    "                        u_sum += c_jk*xi[4*(i_1+N_trunc*i_2)-4,j,k]*np.cos(i_1*j_eval)*np.cos(i_2*k_eval)\n",
    "                        u_sum += c_jk*xi[4*(i_1+N_trunc*i_2)-3,j,k]*np.cos(i_1*j_eval)*np.sin(i_2*k_eval)\n",
    "                        u_sum += c_jk*xi[4*(i_1+N_trunc*i_2)-2,j,k]*np.sin(i_1*j_eval)*np.cos(i_2*k_eval)\n",
    "                        u_sum += c_jk*xi[4*(i_1+N_trunc*i_2)-1,j,k]*np.sin(i_1*j_eval)*np.sin(i_2*k_eval)\n",
    "    return u_sum\n",
    "    \n",
    "''' Policy from berkeley course '''\n",
    "def policy(obs):\n",
    "    return policy_fn(obs[None,:])\n",
    "print('loading and building expert policy')\n",
    "policy_fn = load_policy.load_policy('/Users/torbensell/Dropbox (Cambridge University)/UNI/CAM/PhD/Programme/BIRL_NN_pCN/homework/hw1/experts/HalfCheetah-v2.pkl')\n",
    "print('loaded and built')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - ANALYTICS\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "''' Progress bar to know how much longer one has to wait '''\n",
    "def progressBar(t,value, t_max, acceptances, bar_length=40):\n",
    "    percent = float(t) / t_max\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    sys.stdout.write(\"\\rIteration: {0}    Acceptance ratio: {1}    Percent: [{2}] {3}%  \".format(value,round(acceptances/value,3),arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush()   \n",
    "    \n",
    "''' Plotting a value function '''    \n",
    "def func_plot(xi,name):\n",
    "    x = np.arange(obs_min[0],obs_max[0],0.02)\n",
    "    y = np.arange(obs_min[1],obs_max[1],0.05)\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    Z = np.zeros(X.shape)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            x=np.zeros(dim)\n",
    "            x[0]=X[i,j]\n",
    "            x[1]=Y[i,j]\n",
    "            Z[i,j] = u(xi,x)\n",
    "            \n",
    "    fig = plt.figure()\n",
    "    ax = fig.gca(projection='3d')\n",
    "    surf = ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.RdBu,linewidth=0, antialiased=False)\n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "    ax.set_xlabel('x-axis')\n",
    "    ax.set_ylabel('y-axis')\n",
    "    ax.set_zlabel('z-axis')\n",
    "    ax.view_init(elev=25, azim=-120)\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    fig.savefig(name + '.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "def trajectory_plot(xi,name):\n",
    "    x = np.arange(len(xi))\n",
    "    fig = plt.figure()\n",
    "    plt.plot(x,xi)\n",
    "    fig.savefig(name + '.png', bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "def autocorr(x,lags):\n",
    "    mean=np.mean(x)\n",
    "    var=np.var(x)\n",
    "    xp=x-mean\n",
    "    corr=[1. if l==0 else np.sum(xp[l:]*xp[:-l])/len(x)/var for l in lags]\n",
    "    return np.array(corr)\n",
    "\n",
    "''' Calculate the Effective Sample Size, assumes algorithm already burned in '''\n",
    "def ESS(logposterior,name):\n",
    "    fig, ax = plt.subplots()\n",
    "    N = len(logposterior)\n",
    "    ax.stem(autocorr(logposterior, range(int(N*0.1))),use_line_collection=True) \n",
    "    ESS = N/(1+2*sum(autocorr(logposterior, range(int(N*0.1)))))\n",
    "    print('\\nEffective Sample Size:', round(ESS))\n",
    "    print('Samples required to generate 1 independent sample:', round(N/ESS,2))\n",
    "    fig.savefig(name + '.png', bbox_inches='tight')\n",
    "    plt.close(fig)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Uncertainty Quantification Initialisation\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "x_test = np.load('HC_x_test.npy')\n",
    "v_test = []\n",
    "for i in range(N_a):\n",
    "    v_test.append([])\n",
    "    \n",
    "x_test_100 = np.load('HC_x_test_100.npy')\n",
    "a_test_100 = np.load('HC_a_test_100.npy')\n",
    "optimal_choice = 0\n",
    "not_optimal_choice = 0\n",
    "v_all = np.zeros((N_a,100))\n",
    "\n",
    "def test_value_fn(xi):\n",
    "    for i in range(N_a):\n",
    "        v = u(xi,x_test[i,:])\n",
    "        v_test[i].append(v)\n",
    "        if i>0:\n",
    "            v_test[i][-1]=v_test[i][-1]-v_test[0][-1]\n",
    "    v_test[0][-1] = 0\n",
    "    \n",
    "    global optimal_choice\n",
    "    global not_optimal_choice\n",
    "    v = np.zeros(N_a)\n",
    "    for j in range(100):\n",
    "        for i in range(N_a):\n",
    "            v[i] = u(xi,x_test_100[i,:,j])\n",
    "            v_all[i,j] += v[i]\n",
    "        if a_test_100[j]==np.argmax(v):\n",
    "            optimal_choice += 1\n",
    "        else:\n",
    "            not_optimal_choice += 1\n",
    "            \n",
    "        \n",
    "def boxplot_value_fn():\n",
    "    global v_test\n",
    "    global optimal_choice\n",
    "    global not_optimal_choice\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('UQ of relative value function evaluation')\n",
    "    reward_test = np.load('HC_reward_test.npy')\n",
    "    tags = []\n",
    "    for i in range(N_a):\n",
    "        tags.append(str(round(reward_test[i],2)))\n",
    "    ax.set_xticklabels(tags, rotation=90)\n",
    "    ax.boxplot(v_test)\n",
    "    fig.savefig('figs/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_UQ.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title('UQ of relative value function evaluation')\n",
    "    ax.boxplot(v_test)\n",
    "    fig.savefig('figs/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_UQ_v2.pdf', dpi=300)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    v_test = []\n",
    "    for i in range(N_a):\n",
    "        v_test.append([])\n",
    "        \n",
    "    print('Samples, Correct choices: ',optimal_choice/(optimal_choice+not_optimal_choice))\n",
    "    print('Samples, Wrong choices:   ',not_optimal_choice/(optimal_choice+not_optimal_choice))\n",
    "    \n",
    "    ''' Mean values '''\n",
    "    optimal_choice = 0\n",
    "    not_optimal_choice = 0\n",
    "    \n",
    "    for j in range(100):\n",
    "        for i in range(N_a): \n",
    "            if a_test_100[j]==np.argmax(v_all[:,j]):\n",
    "                optimal_choice += 1\n",
    "            else:\n",
    "                not_optimal_choice += 1\n",
    "                \n",
    "    print('Mean,    Correct choices: ',optimal_choice/(optimal_choice+not_optimal_choice))\n",
    "    print('Mean,    Wrong choices:   ',not_optimal_choice/(optimal_choice+not_optimal_choice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - MCMC (pCN/pCNL)\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "def acceptance_prop(xi_u, xi_v,data,ll_u,diff_u=False):\n",
    "    accept_prop = -ll_u\n",
    "    ll_v = 0\n",
    "        \n",
    "    for j in range(data.shape[0]):\n",
    "        lh = likelihood(xi_v,data[j,:])\n",
    "        ll_v += np.log(lh)\n",
    "    accept_prop += ll_v\n",
    "        \n",
    "    ''' Only pCNL (has extra terms) '''\n",
    "    if method=='pCNL':\n",
    "        accept_prop += -np.sum((xi_v-xi_u)*diff_u)/2 - delta*np.sum((xi_u+xi_v)*diff_u)/4 + delta*np.linalg.norm(diff_u*C_root)**2/4\n",
    "        diff_v = diff_ll(xi_v,data)\n",
    "        accept_prop -= -np.sum((xi_u-xi_v)*diff_v)/2 - delta*np.sum((xi_v+xi_u)*diff_v)/4 + delta*np.linalg.norm(diff_v*C_root)**2/4\n",
    "        return min(1, np.exp(accept_prop)),ll_v,diff_v\n",
    "    else:\n",
    "        return min(1, np.exp(accept_prop)),ll_v\n",
    "    \n",
    "def propose(xi,diff=False):\n",
    "    if method=='pCNL':\n",
    "        proposal = ((2-delta)*xi + 2*delta*C*diff + np.sqrt(8*delta)*sample_prior())/(2+delta)     \n",
    "    else:\n",
    "        proposal = np.sqrt(1-beta*beta)*xi+beta*sample_prior()\n",
    "    return proposal\n",
    "\n",
    "def MCMC(xi,N_data,data,max_time):   \n",
    "    print('\\nMCMC algorithm ('+method + ', N_trunc=' + str(N_trunc) + ', N_data=' + str(N_data) + ', ' + str(max_time) + ' seconds) was started: ' + str(time.ctime()))\n",
    "      \n",
    "    acc_ratio = 0\n",
    "    logposterior = []\n",
    "    logp = []\n",
    "    logl = []\n",
    "    \n",
    "    ''' Initialise likelihood and gradient '''  \n",
    "    ll = loglikelihood(xi,data)\n",
    "    print('Initial loglikelihood: ',ll)\n",
    "    if method=='pCNL' or method=='CNL':\n",
    "        diff = diff_ll(xi,data)\n",
    "    \n",
    "    ''' Run MCMC '''\n",
    "    start = time.time() \n",
    "    j = 0\n",
    "    it = 0\n",
    "    while(time.time()-start<max_time):\n",
    "        \n",
    "        ''' Propose and calculate acceptance probability '''\n",
    "        if method=='pCNL' or method=='CNL':\n",
    "            xi_proposal = propose(xi,diff)  \n",
    "            a,ll_proposal,diff_proposal = acceptance_prop(xi,xi_proposal,data,ll,diff)\n",
    "        else:\n",
    "            xi_proposal = propose(xi)  \n",
    "            a,ll_proposal = acceptance_prop(xi,xi_proposal,data,ll)\n",
    "        \n",
    "        ''' Accept or reject proposal '''\n",
    "        uni = np.random.uniform()\n",
    "        if uni < a or unadjusted:\n",
    "            if method=='pCNL' or method=='CNL':\n",
    "                diff = diff_proposal\n",
    "            xi = xi_proposal    \n",
    "            ll = ll_proposal\n",
    "            acc_ratio = acc_ratio + 1\n",
    "\n",
    "        ''' prior, likelihood, and posterior traceplots are appended '''\n",
    "        lp = logprior(xi)\n",
    "        logposterior.append(lp+ll)\n",
    "        logp.append(lp)\n",
    "        logl.append(ll)\n",
    "        \n",
    "        if prior_compare and j%10==0:\n",
    "            ''' store value function evaluations for uncertainty estimates '''\n",
    "            test_value_fn(xi)\n",
    "        elif policy_compare and (time.time()-start)>it*t_max/1000 and it<1000:\n",
    "            ''' store sample for future use '''\n",
    "            np.save('np_saved/HC/samples_policy_learning/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_sampleNo'+str(it)+'.npy',xi)\n",
    "            it += 1\n",
    "        \n",
    "        if method=='pCNL' or method=='CNL':\n",
    "            progressBar(time.time()-start,j+1,max_time,acc_ratio)\n",
    "        elif (j+1)%100==0:\n",
    "            progressBar(time.time()-start,j+1,max_time,acc_ratio)\n",
    "        j+=1\n",
    "        \n",
    "    progressBar(max_time,j,max_time,acc_ratio)\n",
    "    \n",
    "    acc_ratio = acc_ratio/(j)\n",
    "    print('\\nMCMC algorithm terminated: ' + str(time.ctime()) + '. \\nRuntime = ' + str(time.time()-start))\n",
    "    print('Final loglikelihood: ',ll)\n",
    "    print('Acceptance ratio is ',acc_ratio)\n",
    "    \n",
    "    np.save('np_saved/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample.npy',xi)\n",
    "    \n",
    "    trajectory_plot(logposterior[1:],'figs/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_logposterior')\n",
    "    trajectory_plot(logp[1:],'figs/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_logprior')\n",
    "    trajectory_plot(logl[1:],'figs/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_loglikelihood')\n",
    "    if prior_compare:\n",
    "        boxplot_value_fn()\n",
    "\n",
    "    func_plot(xi,'figs/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample')\n",
    "    \n",
    "    ESS(logposterior,'figs/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_autocorr')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROGRAMMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MCMC algorithm (pCN, N_trunc=10, N_data=100, 86400 seconds) was started: Sun Jul 12 21:18:55 2020\n",
      "Initial loglikelihood:  -68.29045368692636\n",
      "Iteration: 140104    Acceptance ratio: 0.238    Percent: [--------------------------------------->] 100%  \n",
      "MCMC algorithm terminated: Mon Jul 13 21:18:56 2020. \n",
      "Runtime = 86400.2601120472\n",
      "Final loglikelihood:  -78.37091158961736\n",
      "Acceptance ratio is  0.23843002341118028\n",
      "Samples, Correct choices:  0.2012375990293341\n",
      "Samples, Wrong choices:    0.7987624009706659\n",
      "Mean,    Correct choices:  0.25\n",
      "Mean,    Wrong choices:    0.75\n",
      "\n",
      "Effective Sample Size: 211.0\n",
      "Samples required to generate 1 independent sample: 664.91\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "MAIN PROGRAMME 1 - compare NN prior to KL prior (large number of parameters)\n",
    "\n",
    "\"\"\"    \n",
    "\n",
    "prior_compare = True\n",
    "policy_compare = False  \n",
    "\n",
    "# set maximal runtime\n",
    "t_max = 3600*24\n",
    "\n",
    "optimal_choice = 0\n",
    "not_optimal_choice = 0\n",
    "\n",
    "N_trunc = 10 # make sure to restart the kernel and recompile the numba compiled code\n",
    "ev_1 = eigenvalues_1()\n",
    "ev_2 = eigenvalues_2()\n",
    "C,C_root = C_init()\n",
    "\n",
    "# Sample from the prior to see what a sample looks like\n",
    "xi = sample_prior()\n",
    "func_plot(xi,'figs/HC/KL_'+str(N_trunc)+'_a_prior_sample')\n",
    "\n",
    "env = gym.make('HalfCheetah-v2')\n",
    "env.unwrapped\n",
    "env.reset()\n",
    "    \n",
    "try:\n",
    "    data = np.load('HC_data.npy')\n",
    "except FileNotFoundError:\n",
    "    print('\\nNo data found - create data!\\n')\n",
    "N_data = 100\n",
    "    \n",
    "''' run pCN '''\n",
    "method = 'pCN'\n",
    "stochastic_gradients = False # if true then unadjusted needs to be true too\n",
    "unadjusted = False\n",
    "beta = 1/16\n",
    "try:\n",
    "    xi = np.load('np_saved/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample.npy')\n",
    "except FileNotFoundError:\n",
    "    print('\\nStarting from close to 0')\n",
    "    xi = sample_prior(beta)\n",
    "MCMC(xi,N_data,data[50:50+N_data,:],t_max) \n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MCMC algorithm (pCNL, N_trunc=5, N_data=100, 86400 seconds) was started: Tue Jul 21 09:04:37 2020\n",
      "Initial loglikelihood:  -70.65911151775056\n",
      "Iteration: 33242    Acceptance ratio: 0.592    Percent: [--------------------------------------->] 100%  \n",
      "MCMC algorithm terminated: Wed Jul 22 09:04:41 2020. \n",
      "Runtime = 86401.55527281761\n",
      "Final loglikelihood:  -79.06841893579815\n",
      "Acceptance ratio is  0.5920221406654232\n",
      "\n",
      "Effective Sample Size: 6.0\n",
      "Samples required to generate 1 independent sample: 5901.45\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "MAIN PROGRAMME 2 - LEARN policy, and store samples for future use (small number of parameters)\n",
    "\n",
    "\"\"\"    \n",
    "\n",
    "prior_compare = False\n",
    "policy_compare = True   \n",
    "\n",
    "# set maximal runtime\n",
    "t_max = 3600*24\n",
    "\n",
    "N_trunc = 5 # make sure to restart the kernel and recompile the numba compiled code\n",
    "ev_1 = eigenvalues_1()\n",
    "ev_2 = eigenvalues_2()\n",
    "C,C_root = C_init()\n",
    "\n",
    "# Sample from the prior to see what a sample looks like\n",
    "xi = sample_prior()\n",
    "func_plot(xi,'figs/HC/KL_'+str(N_trunc)+'_a_prior_sample')\n",
    "\n",
    "env = gym.make('HalfCheetah-v2')\n",
    "env.unwrapped\n",
    "env.reset()\n",
    "    \n",
    "try:\n",
    "    data = np.load('HC_data.npy')\n",
    "except FileNotFoundError:\n",
    "    print('\\nNo data found - create data!\\n')\n",
    "N_data = 100\n",
    "    \n",
    "    \n",
    "''' run pCN '''\n",
    "method = 'pCN'\n",
    "stochastic_gradients = False # if true then unadjusted needs to be true too\n",
    "unadjusted = False\n",
    "beta = 1/16\n",
    "try:\n",
    "    xi = np.load('np_saved/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample.npy')\n",
    "except FileNotFoundError:\n",
    "    print('\\nStarting from close to 0')\n",
    "    xi = sample_prior(beta)\n",
    "MCMC(xi,N_data,data[50:50+N_data,:],t_max) \n",
    "\n",
    "''' run pCNL '''\n",
    "method = 'pCNL'\n",
    "stochastic_gradients = False # if true then unadjusted needs to be true too\n",
    "unadjusted = False\n",
    "delta = 1/5800\n",
    "try:\n",
    "    xi = np.load('np_saved/HC/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_lastSample.npy')\n",
    "except FileNotFoundError:\n",
    "    print('\\nStarting from close to 0')\n",
    "    xi = sample_prior(delta)\n",
    "MCMC(xi,N_data,data[50:50+N_data,:],t_max) \n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
