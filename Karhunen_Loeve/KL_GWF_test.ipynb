{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sigma = 0.01                        # noise\n",
    "dim = 2                             # dimensionality of the space (v: R^d --> R)\n",
    "obs_min = np.array([0,0])\n",
    "obs_max = np.array([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - LIKELIHOOD \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "m = 21\n",
    "\n",
    "# Define h where it is fixed (when x_2=0 or x_2=1).\n",
    "h_first_row = np.zeros(m)\n",
    "h_last_row = np.zeros(m)\n",
    "for i in range(m): # Points on the bottom, where x_2=0 (h=x_1)\n",
    "    h_first_row[i] = i/(m-1)\n",
    "for i in range(m): # Points on top, where x_2=1 (h=1-x_1)\n",
    "    h_last_row[i] = 1-i/(m-1)\n",
    "    \n",
    "\"\"\"\n",
    "Initialise the finite difference scheme.\n",
    "\"\"\"\n",
    "@numba.njit()\n",
    "def A_init(k):   \n",
    "    A = np.zeros((m**2,m**2))\n",
    "    for j in range(m-2): # central points\n",
    "        for i in range(m-2):\n",
    "            A[(i+1)+m*(j+1),(i+1)+m*(j+1)] = 2*k[(i+1)+m*(j+1)]+k[(i)+m*(j+1)]+k[(i+1)+m*(j)]\n",
    "            A[(i+1)+m*(j+1),(i)+m*(j+1)] = -k[(i)+m*(j+1)]\n",
    "            A[(i+1)+m*(j+1),(i+1)+m*(j)] = -k[(i+1)+m*(j)]\n",
    "            A[(i+1)+m*(j+1),(i+2)+m*(j+1)] = -k[(i+1)+m*(j+1)]\n",
    "            A[(i+1)+m*(j+1),(i+1)+m*(j+2)] = -k[(i+1)+m*(j+1)]\n",
    "    i = m-1 # Points on the right, where x=6 (h_x=0)\n",
    "    for j in range(m-2):\n",
    "        A[i+m*(j+1),i+m*(j+1)] = k[i+m*(j+1)]+k[i+m*(j)]+k[i-1+m*(j+1)]\n",
    "        A[i+m*(j+1),i+m*(j)] = -k[i+m*(j)]\n",
    "        A[i+m*(j+1),i+m*(j+2)] = -k[i+m*(j+1)]\n",
    "        A[i+m*(j+1),i-1+m*(j+1)] = -k[i-1+m*(j+1)]\n",
    "    i = 0 # Points on the left, where x=0 (h_x=0)\n",
    "    for j in range(m-2):\n",
    "        A[i+m*(j+1),i+m*(j+1)] = 2*k[i+m*(j+1)]+k[i+m*(j)]\n",
    "        A[i+m*(j+1),i+m*(j)] = -k[i+m*(j)]\n",
    "        A[i+m*(j+1),(i+1)+m*(j+1)] = -k[i+m*(j+1)]\n",
    "        A[i+m*(j+1),i+m*(j+2)] = -k[i+m*(j+1)]       \n",
    "    # Corner points are already considered in the cases where x_2=0 and x_2=1.'''   \n",
    "    A = 1/((6/(m-1))**2)*A   # Multiply by 1/Delta^2\n",
    "    return A\n",
    "\n",
    "\"\"\"\n",
    "G maps a function u to the output of a PDE, h. It makes use of the finite \n",
    "difference approximation given by A.k and b_k. It's specific for the problem\n",
    "setup.\n",
    "\"\"\"\n",
    "@numba.njit()\n",
    "def G(k):    \n",
    "    A_k = A_init(k)\n",
    "    h = np.zeros(m**2)\n",
    "    b = np.zeros(m**2)\n",
    "    for i in range(m):\n",
    "        b[i+m] -= A_k[i+m,i]*h_first_row[i]\n",
    "        b[i+m*(m-2)] -= A_k[i+m*(m-2),i+m*(m-1)]*h_last_row[i]        \n",
    "        \n",
    "    # As the first and last column are fixed, we only consider a subset of the problem for the linalg solver.\n",
    "    h_sub = np.zeros(m*(m-2))     \n",
    "    A_sub = A_k[:,m:m*(m-1)]\n",
    "    A_sub = A_sub[m:m*(m-1),:]\n",
    "    h_sub = np.linalg.solve(A_sub,b[m:m*(m-1)])\n",
    "\n",
    "    h[m:m*(m-1)] = h_sub\n",
    "    h[0:m] = h_first_row\n",
    "    h[m*(m-1):] = h_last_row    \n",
    "    return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "FUNCTIONS - VALUE FUNCTION AND POLICIES\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "''' Progress bar to know how much longer one has to wait '''\n",
    "def progressBar(value, endvalue, bar_length=40):\n",
    "    percent = float(value) / endvalue\n",
    "    arrow = '-' * int(round(percent * bar_length)-1) + '>'\n",
    "    spaces = ' ' * (bar_length - len(arrow))\n",
    "    sys.stdout.write(\"\\rPercent: [{0}] {1}%\".format(arrow + spaces, int(round(percent * 100))))\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "''' u(xi,x), which evaluates the function u with coefficients xi at x=(pos,speed) --- new, complicated, but fast version '''\n",
    "@numba.njit()\n",
    "def u(xi,x):\n",
    "    u_sum = 0\n",
    "    for i in range(N_trunc):\n",
    "        for j in range(N_trunc):\n",
    "            i_eval = np.pi*(i+1/2)*x[0]\n",
    "            j_eval = np.pi*(j+1/2)*x[1]\n",
    "            u_sum += xi[i,j]*np.cos(i_eval)*np.cos(j_eval)\n",
    "    return 2*u_sum\n",
    "\n",
    "''' Plotting a mean function exp(u) '''    \n",
    "def mean_func_plot(name):\n",
    "    x = np.arange(0,1,0.01)\n",
    "    y = np.arange(0,1,0.01)\n",
    "    X,Y = np.meshgrid(x,y)\n",
    "    Z = np.zeros(X.shape)\n",
    "    \n",
    "    for it in range(8000):\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[1]):\n",
    "                x=np.zeros(dim)\n",
    "                x[0]=X[i,j]\n",
    "                x[1]=Y[i,j]\n",
    "                Z[i,j] += np.exp(u(xi[it],x))/8000\n",
    "                \n",
    "#     for i in range(X.shape[0]):\n",
    "#         for j in range(X.shape[1]):\n",
    "#             Z[i,j] = np.exp(Z[i,j])\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    c = ax.pcolormesh(X, Y, Z, cmap='cool', vmin=Z.min(), vmax=Z.max())\n",
    "    \n",
    "    # set the limits of the plot to the limits of the data\n",
    "    ax.axis([X.min(), X.max(), Y.min(), Y.max()])\n",
    "    fig.colorbar(c, ax=ax)\n",
    "    fig.savefig(name + '.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "    \n",
    "''' Check the predicitve posterior '''\n",
    "def data_prediction_check(name):\n",
    "    \n",
    "    ''' load data and observation points '''\n",
    "    N_data = 33\n",
    "    data = np.load('GWF_data.npy')\n",
    "    obs_indices = np.load('GWF_obs_indices.npy')\n",
    "    \n",
    "    ''' Inititalise list for predicted data and for the labels '''\n",
    "    y_rep = []\n",
    "    labels = []\n",
    "    for i in range(N_data):\n",
    "        y_rep.append([])\n",
    "        x = (obs_indices[i]%m)/(m-1)\n",
    "        y = ((obs_indices[i]-obs_indices[i]%m)/m)/(m-1)\n",
    "        labels.append(str((x,y)))\n",
    "    \n",
    "    for it in range(8000):\n",
    "        progressBar(it,8000)\n",
    "    \n",
    "        k = np.zeros(m**2)\n",
    "        for j in range(m):\n",
    "            for i in range(m):\n",
    "                k[i+m*j] = np.exp(u(xi[it],(i/(m-1),j/(m-1))))\n",
    "        h = G(k)\n",
    "        y_h = h[obs_indices]\n",
    "        \n",
    "        ''' Create data predictions '''\n",
    "        for i in range(N_data):\n",
    "            if noise:\n",
    "                y_rep[i].append(y_h[i]+sigma*np.random.normal())\n",
    "            else:\n",
    "                y_rep[i].append(y_h[i])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.boxplot(y_rep)\n",
    "    ax.set_xticklabels(labels, rotation=90)\n",
    "\n",
    "    ''' Print true data points '''\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(33):\n",
    "        x.append(i+1)\n",
    "        y.append(data[i])\n",
    "    ax.plot(x, y, \"o\")\n",
    "    \n",
    "    fig.savefig(name + '.pdf', dpi=300, bbox_inches='tight')\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAIN PROGRAMME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent: [--------------------------------------->] 100%"
     ]
    }
   ],
   "source": [
    "\"\"\" load samples - pCN \"\"\"\n",
    "\n",
    "method = 'pCN'\n",
    "N_data = 33\n",
    "N_trunc = 25\n",
    "\n",
    "xi = []\n",
    "for it in range(8000):\n",
    "    xi.append(np.load('np_saved/GWF/samples_policy_learning/KL_'+str(N_trunc)+'_'+method+'_NData'+str(N_data)+'_sampleNo'+str(it)+'.npy'))\n",
    "      \n",
    "noise = True\n",
    "data_prediction_check('figs/GWF/GWF_KL_prediction_check')\n",
    "noise = False\n",
    "data_prediction_check('figs/GWF/GWF_KL_prediction_check_no_noise')\n",
    "\n",
    "mean_func_plot('figs/GWF/GWF_KL_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
